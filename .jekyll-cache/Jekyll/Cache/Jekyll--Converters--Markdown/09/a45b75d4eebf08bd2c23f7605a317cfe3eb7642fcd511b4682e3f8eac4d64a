I"Ó2<p>Imagina que un canal de televisi√≥n pudiera crear mediante Inteligencia Artificial (IA) una copia digital de su presentador principal, permiti√©ndole hacer suplencias en algunas secciones del informativo o incluso presentar otros programas. No se trata de ciencia ficci√≥n. Es algo que ya est√° ocurriendo en India, Kuwait, Indonesia y China, donde la empresa surcoreana Deep Brain AI trabaja con cuatro cadenas diferentes en la creaci√≥n de gemelos digitales de sus presentadores que ya aparecen en avances informativos.</p>

<p><img src="/blog/images/shots/diapositiva3.jpg" alt="" /></p>

<h3 id="la-r√°pida-incorporaci√≥n-de-presentadores-virtuales-en-informativos-de-todo-el-mundo"><strong>La r√°pida incorporaci√≥n de presentadores virtuales en informativos de todo el mundo</strong></h3>

<p>La primera presentadora virtual del mundo, Ananova, fue lanzada por la empresa PA Media en el a√±o 2000. Su voz sintetizada cuenta las noticias, acompa√±ada de fotograf√≠as que ilustran las informaciones. Incluso hoy nos llama la atenci√≥n ver el rostro en movimiento de Ananova; sus gestos son casi perfectos. A pesar de las limitaciones t√©cnicas en la imagen digital, la invenci√≥n de Ananova marc√≥ tres claras ventajas de los presentadores virtuales: la velocidad en la generaci√≥n de noticias, la posibilidad de emisi√≥n ininterrumpida las 24 horas y una precisi√≥n milim√©trica que le impide cometer errores. Adem√°s, estos presentadores, a diferencia de los humanos, no se quejan de molestias, no necesitan descansos, ni tampoco piden incrementos salariales‚Ä¶</p>

<p><img src="/blog/images/shots/diapositiva4.jpg" alt="" /></p>

<p>En 2016, la presentadora virtual Kizuna AI surgi√≥ en YouTube. Con una adorable imagen bidimensional, una voz alegre y un sofisticado lenguaje corporal, Kizuna fue la embajadora de la campa√±a ‚ÄúVen a Jap√≥n‚Äù y atrajo a m√°s de 3 millones de fans. En 2018, <a href="https://mip.umh.es/blog/2019/11/02/el-impacto-de-la-inteligencia-artificial-en-el-periodismo/">la agencia de noticias Xinhua lanz√≥ dos presentadores virtuales superrealistas</a> en la quinta Conferencia Mundial de Internet. La identidad del cada robot se simul√≥ a partir de las voces, los movimientos de labios y las expresiones de dos presentadores reales de la agencia de noticias. Las primeras versiones mostraban una falta de calidez y cierto automatismo, pero los ingenieros trabajaron para dotarles de m√°s humanidad y sentido del humor. <a href="https://www.latimes.com/business/la-fi-ai-newsanchors-20181109-story.html">Como observ√≥ un analista</a>: ‚ÄúDesde fuera, son casi indistinguibles de sus hom√≥logos humanos, con trajes n√≠tidos y pelo ordenado‚Ä¶ los presentadores tienen la voz, las expresiones faciales y las acciones de una persona real‚Äù.</p>

<p>‚ÄúSoy Fedha, la primera presentadora de Kuwait con IA en Kuwait News. ¬øQu√© noticias prefieres? Escuchamos vuestras opiniones‚Äù, anunci√≥ en √°rabe en Twitter en abril de 2023. Un directivo de Kuwait Times <a href="https://www.adweek.com/tvspy/kuwait-news-outlet-unveils-ai-anchor-named-fedha/247939/">declar√≥ a The Guardian</a> que Fedha demostraba el potencial de la IA para ofrecer ‚Äúcontenidos nuevos e innovadores‚Äù. La moda est√° en pleno auge en canales de una decena de pa√≠ses. Desde finales de 2022, Nadira, la primera presentadora virtual de Indonesia, cuenta las noticias en varios idiomas en el canal 1. Y en Filipinas, el gigante audiovisual GMA Network Inc. utiliza la IA para generar noticias sobre el deporte mediante avatares de presentadores desde enero de 2023.</p>

<p>Los canales de noticias indios van un paso por delante con sus propios presentadores virtuales, que ya reciben una gran aceptaci√≥n entre millones de espectadores. Desde Lisa en OTV hasta Sana en Aaj Tak, pasando por AI Kaur en News18 Punjab Haryana y Soundrya en Power TV, los canales de noticias hindi y regionales han apostado decididamente por incorporar a los presentadores generados mediante IA. Sin embargo, no es oro todo lo que reluce. Algunos analistas consideran que estos canales intentan proyectar una imagen de vanguardia tecnol√≥gica y cautivar a una audiencia cada vez menos cr√≠tica con las informaciones robotizadas. Tambi√©n se trata de una enorme operaci√≥n de marketing. ‚ÄúUsan la IA de forma muy limitada, es como una mu√±eca Barbie que habla alimentada con noticias elaboradas. ¬øAcaso el presentador creado por la IA tiene libertad para elegir las noticias y los elementos audiovisuales? No es m√°s que una acci√≥n de marketing que busca aumentar los ratings‚Äù, explica una experta.</p>

<p><img src="/blog/images/shots/diapositiva1.jpg" alt="" /></p>

<p>El despliegue de los presentadores virtuales crece r√°pidamente, con consecuencias que ya est√°n siendo investigadas por los acad√©micos. <a href="https://www.tandfonline.com/doi/abs/10.1080/03623319.2022.2027163">Un estudio reciente sugiere</a> que, al ver una informaci√≥n meteorol√≥gica, el espectador percibe que un locutor humano es m√°s cre√≠ble que un locutor generado mediante IA. Sin embargo, la intenci√≥n de buscar informaci√≥n y el comportamiento asociado a las noticias no mostraron diferencias significativas entre los locutores humanos y los virtuales. Adem√°s, <a href="https://www.ideals.illinois.edu/items/126773">una tesis doctoral concluye</a> que, en comparaci√≥n con un locutor humano, un locutor virtual ultrarrealista no genera diferencias significativas en la asignaci√≥n de los recursos cognitivos para codificar el contenido de las noticias, la valoraci√≥n subjetiva y la emoci√≥n que las informaciones generaban.</p>

<p>Estas diferencias m√≠nimas o nulas en las respuestas de la audiencia ante los presentadores humanos y los virtuales concuerdan con las predicciones del <a href="https://stars.library.ucf.edu/cgi/viewcontent.cgi?article=1020&amp;context=hmc">paradigma de los ordenadores como actores sociales</a> (CASA en sus siglas en ingl√©s). En la d√©cada de los noventa, una investigaci√≥n de Nass y su equipo propuso el paradigma CASA bas√°ndose en una serie de experimentos en los que se sustitu√≠an los roles humanos por la tecnolog√≠a inform√°tica. El paradigma CASA postula que las personas tratan a los robots como si fueran personas reales y responden a la tecnolog√≠a de modo adaptativamente social. La din√°mica CASA se atribuye a la tendencia humana de mostrarse menos cr√≠tica al interactuar con los equipos inform√°ticos y herramientas robotizadas.</p>

<p>###<strong>Riesgos y √©tica del uso de los presentadores virtuales en las noticias</strong></p>

<p>Es una industria en r√°pido crecimiento, cuando empiezan a incorporarse periodistas virtuales que tienen una estrecha relaci√≥n con los humanos, la mayor√≠a de los directivos de medios confiesa que ‚Äúest√°n aprendiendo sobre la marcha‚Äù. Pero lo consideran una herramienta m√°s para crear contenidos y la IA ya se aplica en m√∫ltiples etapas del proceso de producci√≥n audiovisual. ‚ÄúAl igual que un programa de edici√≥n de v√≠deo, los presentadores virtuales son otra herramienta m√°s en este proceso‚Äù, justifican algunos profesionales.</p>

<p>Sin embargo, estos experimentos pueden servir para ocultar la necesidad de discriminar las fuentes de informaci√≥n objetiva para la audiencia. El impacto a largo plazo puede hacer que los espectadores empiecen a dudar de su fiabilidad y aumente la desconfianza hacia los medios de comunicaci√≥n que usan presentadores virtuales. Cabe preguntarse ¬øpor qu√© no utilizan estos gemelos virtuales ni Reuters, ni AP, ni los canales de noticias norteamericanos?</p>

<p>En algunos casos, los presentadores generados con IA se est√°n convirtiendo en ‚Äúmarionetas virtuales‚Äù que ganan adeptos en los estados autoritarios. Esos presentadores virtuales no cuestionan las noticias que se les dan y que luego ‚Äúvomitan‚Äù de forma autom√°tica. No hace falta controlar a una marioneta, porque ya est√° controlada, a trav√©s de los hilos sus due√±os la manejan a su antojo. Sus amos controlan el mensaje, sin las molestas ‚Äúinterferencias‚Äù por parte de un periodista humano. En algunos casos apelan a las emociones m√°s b√°sicas, mediante presentadoras atractivas que cautivan a los espectadores.</p>

<p><img src="/blog/images/shots/diapositiva5.jpg" alt="" /></p>

<p>La √©tica apela a la responsabilidad social e implica necesariamente informar para qu√© se utiliza la IA en cada caso. Ser transparentes y explicar en qu√© aspectos se ha empleado. Se recomienda utilizarla s√≥lo cuando puede mejorar los procesos de producci√≥n y gesti√≥n de la informaci√≥n y en definitiva, contribuir a un periodismo de mayor calidad. Si un medio quiere realmente servir a su audiencia, debe utilizar la IA precisamente para elaborar reportajes profundos y ampliar el alcance de su cobertura ya que con la IA podemos llegar a m√°s cosas, se pueden recopilar m√°s datos a mayor velocidad. Las herramientas de IA deben utilizarse en la comprobaci√≥n de los rumores, la detecci√≥n de bulos y el seguimiento de los canales de desinformaci√≥n.</p>

<p>Los avances en IA <a href="https://mip.umh.es/blog/2019/12/01/deepfakes-c%C3%B3mo-los-medios-combaten-la-desinformaci%C3%B3n-m%C3%A1s-sofisticada/">han avivado la alarma mundial</a> por el potencial de la tecnolog√≠a para la desinformaci√≥n y el uso indebido, con im√°genes falsas creadas de la nada y personas que dicen cosas que nunca dijeron. En marzo de 2022, Meta, propietaria de Facebook, <a href="https://www.elconfidencial.com/tecnologia/novaceno/2022-03-17/hackers-rusos-difunden-un-video-falso-de-zelensky-ordenando-la-rendicion_3393225/">retir√≥ un v√≠deo falso</a> en el que el presidente ucraniano, Volodymyr Zelenskyy, instaba a los ciudadanos a deponer las armas y rendirse a Rusia.</p>

<p><a href="https://www.nytimes.com/2023/02/07/technology/artificial-intelligence-training-deepfake.html">Seg√∫n publicaba The New York Times en febrero de 2023</a> un informe de la empresa de investigaci√≥n Graphika alert√≥ de que agentes chinos alineados con el Estado utilizaban <em>deepfakes</em> generados por IA para difundir v√≠deos de propaganda pro-china en las redes sociales. Los falsos presentadores de un medio ficticio llamado Wolf News fueron creados por un software de IA y aparecieron en im√°genes en las redes sociales que parec√≠an promover los intereses del Partido Comunista Chino, afirma en su informe la empresa de investigaci√≥n Graphika, con sede en Estados Unidos.</p>

<p><img src="/blog/images/shots/diapositiva2.jpg" alt="" /></p>

<p>‚ÄúEs la primera vez que vemos que una operaci√≥n alineada con el Estado utiliza im√°genes de v√≠deo generadas por IA de una persona ficticia para crear contenido pol√≠tico enga√±oso‚Äù, declar√≥ Jack Stubbs, vicepresidente de Graphika. En uno de los v√≠deos, un presentador ficticio que se hac√≠a llamar Alex criticaba la inacci√≥n de Estados Unidos ante la violencia armada que asola el pa√≠s. En otro, una presentadora subrayaba la necesidad de ‚Äúcooperaci√≥n entre las grandes potencias como China y Estados Unidos‚Äù.</p>

<p>Seg√∫n el informe de Graphika, los dos presentadores de Wolf News hab√≠an sido creados con tecnolog√≠a proporcionada por la empresa de IA Synthesia, con sede en Londres. Graphika descubri√≥ los deepfakes en plataformas como Twitter, Facebook y YouTube mientras rastreaba operaciones de desinformaci√≥n pro-China conocidas como ‚Äúspamouflage‚Äù. ‚ÄúEs una operaci√≥n de influencia prochina que amplifica sobre todo v√≠deos de spam pol√≠tico de baja calidad, lo que demuestra las limitaciones del uso de deepfakes en estas operaciones‚Äù, se√±ala el informe.</p>

<p><a href="https://www.niemanlab.org/2023/07/writing-guidelines-for-the-role-of-ai-in-your-newsroom-here-are-some-er-guidelines-for-that/">Seg√∫n un estudio publicado en el Nieman Lab</a>, al menos 23 grandes medios en todo el mundo ya han elaborado directrices para incorporar el uso de las herramientas de IA con mayor eficacia. Las empresas son conscientes de los riesgos que entra√±a esta tecnolog√≠a tan disruptiva y sopesan cuidadosamente los pros y los contras antes de seguir adelante y desarrollar su estrategia.</p>

<p>Por ejemplo, Guardian News &amp; Media <a href="https://www.theguardian.com/help/insideguardian/2023/jun/16/the-guardians-approach-to-generative-ai">ha creado un grupo de trabajo sobre IA</a> para evaluar c√≥mo debe responder a los riesgos y oportunidades que plantea esta tecnolog√≠a. ‚ÄúSi deseamos incluir elementos significativos generados mediante la IA en un art√≠culo, s√≥lo lo haremos si existen evidencias claras de un beneficio espec√≠fico; se har√° mediante supervisi√≥n humana y con el permiso expl√≠cito de un editor senior‚Äù, se√±al√≥ la directora, Katharine Viner, en junio de 2023. The Guardian afirma que las herramientas de IA generativa son apasionantes, pero todav√≠a poco fiables: ‚ÄúNuestra principal preocupaci√≥n con la IA es la misma que con cualquier otra tecnolog√≠a: la precisi√≥n, la imparcialidad y hacer nuestro mejor trabajo en favor de nuestra comunidad‚Äù.</p>
:ET