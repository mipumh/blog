I":3<p>Imagina que un canal de televisión pudiera crear mediante Inteligencia Artificial (IA) una copia digital de su presentador principal, permitiéndole hacer suplencias en algunas secciones del informativo o incluso presentar otros programas. No se trata de ciencia ficción. Es algo que ya está ocurriendo en India, Kuwait, Indonesia y China, donde la empresa surcoreana Deep Brain AI trabaja con cuatro cadenas diferentes en la creación de gemelos digitales de sus presentadores que ya aparecen en avances informativos.</p>

<p><img src="/blog/images/shots/diapositiva3.jpg" alt="" /></p>

<h3 id="la-rápida-incorporación-de-presentadores-virtuales-en-informativos-de-todo-el-mundo"><strong>La rápida incorporación de presentadores virtuales en informativos de todo el mundo</strong></h3>

<p>La primera presentadora virtual del mundo, Ananova, fue lanzada por la empresa PA Media en el año 2000. Su voz sintetizada cuenta las noticias, acompañada de fotografías que ilustran las informaciones. Incluso hoy nos llama la atención ver el rostro en movimiento de Ananova; sus gestos son casi perfectos. A pesar de las limitaciones técnicas en la imagen digital, la invención de Ananova marcó tres claras ventajas de los presentadores virtuales: la velocidad en la generación de noticias, la posibilidad de emisión ininterrumpida las 24 horas y una precisión milimétrica que le impide cometer errores. Además, estos presentadores, a diferencia de los humanos, no se quejan de molestias, no necesitan descansos, ni tampoco piden incrementos salariales…</p>

<p><img src="/blog/images/shots/diapositiva4.jpg" alt="" /></p>

<p>En 2016, la presentadora virtual Kizuna AI surgió en YouTube. Con una adorable imagen bidimensional, una voz alegre y un sofisticado lenguaje corporal, Kizuna fue la embajadora de la campaña “Ven a Japón” y atrajo a más de 3 millones de fans. En 2018, <a href="https://mip.umh.es/blog/2019/11/02/el-impacto-de-la-inteligencia-artificial-en-el-periodismo/">la agencia de noticias Xinhua lanzó dos presentadores virtuales superrealistas</a> en la quinta Conferencia Mundial de Internet. La identidad del cada robot se simuló a partir de las voces, los movimientos de labios y las expresiones de dos presentadores reales de la agencia de noticias. Las primeras versiones mostraban una falta de calidez y cierto automatismo, pero los ingenieros trabajaron para dotarles de más humanidad y sentido del humor. <a href="https://www.latimes.com/business/la-fi-ai-newsanchors-20181109-story.html">Como observó un analista</a>: “Desde fuera, son casi indistinguibles de sus homólogos humanos, con trajes nítidos y pelo ordenado… los presentadores tienen la voz, las expresiones faciales y las acciones de una persona real”.</p>

<p>“Soy Fedha, la primera presentadora de Kuwait con IA en Kuwait News. ¿Qué noticias prefieres? Escuchamos vuestras opiniones”, anunció en árabe en Twitter en abril de 2023. Un directivo de Kuwait Times <a href="https://www.adweek.com/tvspy/kuwait-news-outlet-unveils-ai-anchor-named-fedha/247939/">declaró a The Guardian</a> que Fedha demostraba el potencial de la IA para ofrecer “contenidos nuevos e innovadores”. La moda está en pleno auge en canales de una decena de países. Desde finales de 2022, Nadira, la primera presentadora virtual de Indonesia, cuenta las noticias en varios idiomas en el canal 1. Y en Filipinas, el gigante audiovisual GMA Network Inc. utiliza la IA para generar noticias sobre el deporte mediante avatares de presentadores desde enero de 2023.</p>

<p>Los canales de noticias indios van un paso por delante con sus propios presentadores virtuales, que ya reciben una gran aceptación entre millones de espectadores. Desde Lisa en OTV hasta Sana en Aaj Tak, pasando por AI Kaur en News18 Punjab Haryana y Soundrya en Power TV, los canales de noticias hindi y regionales han apostado decididamente por incorporar a los presentadores generados mediante IA. Sin embargo, no es oro todo lo que reluce. Algunos analistas consideran que estos canales intentan proyectar una imagen de vanguardia tecnológica y cautivar a una audiencia cada vez menos crítica con las informaciones robotizadas. También se trata de una enorme operación de marketing. “Usan la IA de forma muy limitada, es como una muñeca Barbie que habla alimentada con noticias elaboradas. ¿Acaso el presentador creado por la IA tiene libertad para elegir las noticias y los elementos audiovisuales? No es más que una acción de marketing que busca aumentar los ratings”, explica una experta.</p>

<p><img src="/blog/images/shots/diapositiva1.jpg" alt="" /></p>

<p>El despliegue de los presentadores virtuales crece rápidamente, con consecuencias que ya están siendo investigadas por los académicos. <a href="https://www.tandfonline.com/doi/abs/10.1080/03623319.2022.2027163">Un estudio reciente sugiere</a> que, al ver una información meteorológica, el espectador percibe que un locutor humano es más creíble que un locutor generado mediante IA. Sin embargo, la intención de buscar información y el comportamiento asociado a las noticias no mostraron diferencias significativas entre los locutores humanos y los virtuales. Además, <a href="https://www.ideals.illinois.edu/items/126773">una tesis doctoral concluye</a> que, en comparación con un locutor humano, un locutor virtual ultrarrealista no genera diferencias significativas en la asignación de los recursos cognitivos para codificar el contenido de las noticias, la valoración subjetiva y la emoción que las informaciones generaban.</p>

<p>Estas diferencias mínimas o nulas en las respuestas de la audiencia ante los presentadores humanos y los virtuales concuerdan con las predicciones del <a href="https://stars.library.ucf.edu/cgi/viewcontent.cgi?article=1020&amp;context=hmc">paradigma de los ordenadores como actores sociales</a> (CASA en sus siglas en inglés). En la década de los noventa, una investigación de Nass y su equipo propuso el paradigma CASA basándose en una serie de experimentos en los que se sustituían los roles humanos por la tecnología informática. El paradigma CASA postula que las personas tratan a los robots como si fueran personas reales y responden a la tecnología de modo adaptativamente social. La dinámica CASA se atribuye a la tendencia humana de mostrarse menos crítica al interactuar con los equipos informáticos y herramientas robotizadas.</p>

<h3 id="riesgos-y-ética-del-uso-de-los-presentadores-virtuales-en-las-noticias"><strong>Riesgos y ética del uso de los presentadores virtuales en las noticias</strong></h3>

<p>Es una industria en rápido crecimiento, cuando empiezan a incorporarse periodistas virtuales que tienen una estrecha relación con los humanos, la mayoría de los directivos de medios confiesa que “están aprendiendo sobre la marcha”. Pero lo consideran una herramienta más para crear contenidos y la IA ya se aplica en múltiples etapas del proceso de producción audiovisual. “Al igual que un programa de edición de vídeo, los presentadores virtuales son otra herramienta más en este proceso”, justifican algunos profesionales.</p>

<p>Sin embargo, estos experimentos pueden servir para ocultar la necesidad de discriminar las fuentes de información objetiva para la audiencia. El impacto a largo plazo puede hacer que los espectadores empiecen a dudar de su fiabilidad y aumente la desconfianza hacia los medios de comunicación que usan presentadores virtuales. Cabe preguntarse ¿por qué no utilizan estos gemelos virtuales ni Reuters, ni AP, ni los canales de noticias norteamericanos?</p>

<p>En algunos casos, los presentadores generados con IA se están convirtiendo en “marionetas virtuales” que ganan adeptos en los estados autoritarios. Esos presentadores virtuales no cuestionan las noticias que se les dan y que luego “vomitan” de forma automática. No hace falta controlar a una marioneta, porque ya está controlada, a través de los hilos sus dueños la manejan a su antojo. Sus amos controlan el mensaje, sin las molestas “interferencias” por parte de un periodista humano. En algunos casos apelan a las emociones más básicas, mediante presentadoras atractivas que cautivan a los espectadores.</p>

<p><img src="/blog/images/shots/diapositiva5.jpg" alt="" /></p>

<p>La ética apela a la responsabilidad social e implica necesariamente informar para qué se utiliza la IA en cada caso. Ser transparentes y explicar en qué aspectos se ha empleado. Se recomienda utilizarla sólo cuando puede mejorar los procesos de producción y gestión de la información y en definitiva, contribuir a un periodismo de mayor calidad. Si un medio quiere realmente servir a su audiencia, debe utilizar la IA precisamente para elaborar reportajes profundos y ampliar el alcance de su cobertura ya que con la IA podemos llegar a más cosas, se pueden recopilar más datos a mayor velocidad. Las herramientas de IA deben utilizarse en la comprobación de los rumores, la detección de bulos y el seguimiento de los canales de desinformación.</p>

<p>Los avances en IA <a href="https://mip.umh.es/blog/2019/12/01/deepfakes-c%C3%B3mo-los-medios-combaten-la-desinformaci%C3%B3n-m%C3%A1s-sofisticada/">han avivado la alarma mundial</a> por el potencial de la tecnología para la desinformación y el uso indebido, con imágenes falsas creadas de la nada y personas que dicen cosas que nunca dijeron. En marzo de 2022, Meta, propietaria de Facebook, <a href="https://www.elconfidencial.com/tecnologia/novaceno/2022-03-17/hackers-rusos-difunden-un-video-falso-de-zelensky-ordenando-la-rendicion_3393225/">retiró un vídeo falso</a> en el que el presidente ucraniano, Volodymyr Zelenskyy, instaba a los ciudadanos a deponer las armas y rendirse a Rusia.</p>

<p><a href="https://www.nytimes.com/2023/02/07/technology/artificial-intelligence-training-deepfake.html">Según publicaba The New York Times en febrero de 2023</a> un informe de la empresa de investigación Graphika alertó de que agentes chinos alineados con el Estado utilizaban <em>deepfakes</em> generados por IA para difundir vídeos de propaganda pro-china en las redes sociales. Los falsos presentadores de un medio ficticio llamado Wolf News fueron creados por un software de IA y aparecieron en imágenes en las redes sociales que parecían promover los intereses del Partido Comunista Chino, afirma en su informe la empresa de investigación Graphika, con sede en Estados Unidos.</p>

<p><img src="/blog/images/shots/diapositiva2.jpg" alt="" /></p>

<p>“Es la primera vez que vemos que una operación alineada con el Estado utiliza imágenes de vídeo generadas por IA de una persona ficticia para crear contenido político engañoso”, declaró Jack Stubbs, vicepresidente de Graphika. En uno de los vídeos, un presentador ficticio que se hacía llamar Alex criticaba la inacción de Estados Unidos ante la violencia armada que asola el país. En otro, una presentadora subrayaba la necesidad de “cooperación entre las grandes potencias como China y Estados Unidos”.</p>

<p>Según el informe de Graphika, los dos presentadores de Wolf News habían sido creados con tecnología proporcionada por la empresa de IA Synthesia, con sede en Londres. Graphika descubrió los deepfakes en plataformas como Twitter, Facebook y YouTube mientras rastreaba operaciones de desinformación pro-China conocidas como “spamouflage”. “Es una operación de influencia prochina que amplifica sobre todo vídeos de spam político de baja calidad, lo que demuestra las limitaciones del uso de deepfakes en estas operaciones”, señala el informe.</p>

<p><a href="https://www.niemanlab.org/2023/07/writing-guidelines-for-the-role-of-ai-in-your-newsroom-here-are-some-er-guidelines-for-that/">Según un estudio publicado en el Nieman Lab</a>, al menos 23 grandes medios en todo el mundo ya han elaborado directrices para incorporar el uso de las herramientas de IA con mayor eficacia. Las empresas son conscientes de los riesgos que entraña esta tecnología tan disruptiva y sopesan cuidadosamente los pros y los contras antes de seguir adelante y desarrollar su estrategia.</p>

<p>Por ejemplo, Guardian News &amp; Media <a href="https://www.theguardian.com/help/insideguardian/2023/jun/16/the-guardians-approach-to-generative-ai">ha creado un grupo de trabajo sobre IA</a> para evaluar cómo debe responder a los riesgos y oportunidades que plantea esta tecnología. “Si deseamos incluir elementos significativos generados mediante la IA en un artículo, sólo lo haremos si existen evidencias claras de un beneficio específico; se hará mediante supervisión humana y con el permiso explícito de un editor senior”, señaló la directora, Katharine Viner, en junio de 2023. The Guardian afirma que las herramientas de IA generativa son apasionantes, pero todavía poco fiables: “Nuestra principal preocupación con la IA es la misma que con cualquier otra tecnología: la precisión, la imparcialidad y hacer nuestro mejor trabajo en favor de nuestra comunidad”.</p>
:ET