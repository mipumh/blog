I"F<p>Hace un par de aÃ±os entrevistamos al directivo de una empresa de Inteligencia Artificial (IA) que trabaja en el desarrollo de sistemas automatizados para instituciones y medios de comunicaciÃ³n. Cuando le preguntamos por las implicaciones Ã©ticas de la IA en el periodismo, el directivo pasÃ³ de puntillas por el tema y se limitÃ³ a decir que â€œno es necesario dar a conocer el algoritmo que usa una empresa porque es como la fÃ³rmula de la Coca-colaâ€. DespuÃ©s <a href="https://textualvisualmedia.com/index.php/txtvmedia/article/view/301">hablamos con profesionales de mÃ¡s de 20 medios espaÃ±oles que usaban algÃºn tipo de IA</a> y me sorprendiÃ³ que la mayorÃ­a tambiÃ©n consideraba la Ã©tica como una cuestiÃ³n casi residual. La IA supone un salto cualitativo en el desarrollo tecnolÃ³gico de los medios. La diferencia radical respecto a etapas anteriores consiste en que estas herramientas son capaces de desarrollar tareas por sÃ­ solas, con independencia de la intervenciÃ³n humana. Y sus implicaciones Ã©ticas transforman la naturaleza del periodismo tal y como lo conocemos.</p>

<p><img src="/blog/images/shots/pexels-markus-spiske-1921326.jpg" alt="" />
<sup>Markus Spiske (Pexels)</sup></p>

<p>En enero de 2023, BuzzFeed anunciÃ³ que utilizarÃ¡ la IA para â€œmejorarâ€ sus contenidos y concursos. El medio nativo digital ha llegado a un acuerdo con la empresa de ChatGPT, Open AI, y emplearÃ¡ esta tecnologÃ­a para personalizar sus concursos, aportar ideas y generar algunos contenidos informativos. <a href="https://www.theguardian.com/media/2023/jan/26/buzzfeed-artifical-intelligence-content-quizzes-chatgpt">SegÃºn The Guardian</a>, el CEO Jonah Peretti lo comunicÃ³ a los empleados de BuzzFeed en un correo interno: â€œEn 2023, los contenidos inspirados en la inteligencia artificial pasarÃ¡n de la fase de I+D a formar parte de nuestra actividad principal, mejorando la experiencia de los concursos, aportando ideas y personalizando los contenidos para nuestros usuariosâ€. El anuncio disparÃ³ el valor de las acciones de BuzzFeed.</p>

<p>La integraciÃ³n de la IA en las redacciones es imparable. En este blog <a href="https://mip.umh.es/blog/2019/11/02/el-impacto-de-la-inteligencia-artificial-en-el-periodismo/">hemos analizado su implantaciÃ³n desde 2019</a>, proporcionando ademÃ¡s <a href="https://mip.umh.es/blog/2021/11/24/recursos-para-utilizar-la-inteligencia-artificial-en-el-periodismo/">un listado de recursos para entender su aplicaciÃ³n en los medios</a> o las consecuencias de la desinformaciÃ³n <a href="https://mip.umh.es/blog/2019/12/01/deepfakes-c%C3%B3mo-los-medios-combaten-la-desinformaci%C3%B3n-m%C3%A1s-sofisticada/">mediante <em>deepfakes</em> cada vez mÃ¡s sofisticados</a>. AdemÃ¡s, en enero de 2023, el profesor del MIP FÃ©lix Arias recopilÃ³ <a href="https://mip.umh.es/blog/2023/01/10/mucho-mas-alla-de-chatgpt-80-recursos-basados-en-inteligencia-artificial/">80 herramientas para generar contenidos de texto, audio, imagen y vÃ­deo mediante la IA</a>.Â </p>

<p>Ya es habitual que muchos medios utilicen la IA para redactar noticias, gestionar algoritmos, potenciar los servicios de suscripciÃ³n, procesar cantidades ingentes de datos y generar visualizaciones, entre otras funciones. La implantaciÃ³n de herramientas como ChatGPT, el sistema basado en el modelo de lenguaje por Inteligencia Artificial GPT-3 desarrollado por la empresa OpenAI, puede ayudar a los periodistas (siempre con supervisiÃ³n) <a href="https://www.journalism.co.uk/news/how-can-journalists-use-chatgpt-/s2/a1005273/">en diversas tareas</a>: resumir documentos, buscar nuevos enfoques, extraer citas, transcribir entrevistas, generar titulares, traducir artÃ­culos, redactar correos y textos para redes sociales o contextualizar artÃ­culos. <a href="https://www.yorokobu.es/periodismo-creado-por-maquinas/">Como argumenta Borja Ventura</a>, la IA ya estÃ¡ contribuyendo a mejorar los procesos de documentaciÃ³n, verificaciÃ³n, ediciÃ³n, creaciÃ³n, jerarquizaciÃ³n, perfilado y consumo de los contenidos informativos. AdemÃ¡s, estos sistemas puedenÂ generar imÃ¡genes, editar vÃ­deos o sintetizar conceptos complejos para adaptarlos a distintos tipos de lectores. Sin embargo, el uso de ChatGPT suscita cuestiones Ã©ticas, tales como la violaciÃ³n del derecho de autorÃ­a, la falta de transparencia en las fuentes empleadas, el plagio o la apropiaciÃ³n indebida de textos, imÃ¡genes o vÃ­deos.</p>

<p>Sin embargo, las herramientas de IA distan de ser perfectas. El hecho de queÂ puedan generarÂ falsedadesÂ de forma convincente inquieta a los expertos, ya que pueden incrementar la desinformaciÃ³n <strong>de forma alarmante</strong>. En noviembre de 2022, el medio especializado en tecnologÃ­aÂ <strong>CNET</strong>Â <a href="https://edition.cnn.com/2023/01/25/tech/cnet-ai-tool-news-stories/index.html">utilizÃ³ un generador de textos propio para elaborarÂ artÃ­culosÂ sobre finanzas personales</a>, con la finalidad de mejorar su SEO y posicionarse en lo mÃ¡s alto de las bÃºsquedas en Google. Sin comunicar esa novedad a sus lectores, la empresa publicÃ³ al menos 77 artÃ­culos mediante estaÂ <strong>herramienta</strong>. A principios de enero, varios investigadoresÂ revelaronÂ no solo que <strong>CNET</strong> habÃ­a empleado la IA para generar esos artÃ­culos, sino que su sistema de gestiÃ³n de contenidosÂ publicÃ³ reiteradamente engaÃ±os, errores, plagios e imprecisiones.</p>

<p><img src="/blog/images/shots/pexels-pixabay-50711.jpg" alt="" />
<sup>Pixabay (Pexels)</sup></p>

<p>El desarrollo del periodismo automatizado presenta una complejidad notable porque afecta a diversos Ã¡mbitos de la organizaciÃ³n y en cada uno de ellos se plantean cuestiones Ã©ticas, ya que afectan a muchÃ­simos Ã¡mbitos de la actividad humana. Â Como las definiciones de los Ã¡mbitos Ã©ticos pueden resultar confusas debido a las diversas plataformas existentes, Jeonghye Han, profesora del Departamento de EducaciÃ³n Computacional en Corea, <a href="https://doi.org/10.3390/info13090440">clasifica los Ã¡mbitos Ã©ticos</a> en funciÃ³n de tres plataformas principales: dispositivos informÃ¡ticos, plataformas intermediarias y dispositivos fÃ­sicos. Esta clasificaciÃ³n proporciona un marco Ã©tico que abarca la Ã©tica de la informÃ¡tica, la Ã©tica de la informaciÃ³n, la ciber-Ã©tica, la Ã©tica robÃ³tica y la Ã©tica de la IA.</p>

<p><img src="/blog/images/shots/esferas-Ã©ticas-de-la-ia.png" alt="" />
<sup><em>Information</em>Â 2022,Â <em>13</em>(9), 440;Â <a href="https://doi.org/10.3390/info13090440">https://doi.org/10.3390/info13090440</a></sup></p>

<p>La complejidad es inmensa. Por un lado, surgen dilemas Ã©ticos desde el Ã¡mbito de la tecnologÃ­a, la informÃ¡tica, la robÃ³tica, el procesamiento del lenguaje natural, los algoritmos y el Big Data. Por otro, desde el Ã¡mbito comercial, sobre la Ã©tica los procedimientos financieros, las vÃ­as de ingresos, la captaciÃ³n y mantenimiento de los suscriptores y las estrategias algorÃ­tmicas de marketing personalizado. Desde el Ã¡mbito periodÃ­stico, en el diseÃ±o, producciÃ³n y distribuciÃ³n de contenidos informativos y las prÃ¡cticas en la gestiÃ³n de los procesos automatizados. AdemÃ¡s, en el Ã¡mbito comunicativo destacan las consecuencias de la distribuciÃ³n de informaciones generadas mediante IA, tales como el crecimiento de la desinformaciÃ³n o la creaciÃ³n de â€˜burbujas de contenidoâ€™ algorÃ­tmicas. Se trata de dilemas Ã©ticos que han de afrontarse con responsabilidad.</p>

<p>Hasta ahora, la mayor parte de la automatizaciÃ³n se ha aplicado en informaciones rutinarias: resÃºmenes bursÃ¡tiles, fenÃ³menos naturales, la cobertura de deportes de ligas secundarias o amateurs o informes de resultados de empresas. Sin embargo, de acuerdo con Antonio Ortiz, es previsible que en poco tiempo <a href="https://www.error500.net/p/lo-humano-sera-un-lujo-del-presumible">todo lo humano sea un lujo</a> ya que las tecnologÃ­as basadas en IA desempeÃ±arÃ¡n todo tipo de trabajos, desde atender las llamadas en una empresa hasta servir un pedido en un restaurante de comida rÃ¡pida.</p>

<p>En febrero de 2022,Â  elÂ <a href="https://fcic.periodistes.cat/">Consell de la InformaciÃ³ de Catalunya</a> presentÃ³ el informe â€˜<a href="https://fcic.periodistes.cat/wp-content/uploads/2022/03/algorismes_a_les_redaccions_ESP_.pdf">Algoritmos en las redacciones: retos y recomendaciones para dotar a la Inteligencia Artificial de los valores Ã©ticos del periodismo</a>â€™. El estudio pretende dotar al periodismo de herramientas para convertirse en referente de la tecnoÃ©tica de la comunicaciÃ³n. La coordinadora del informe, la doctora PatrÃ­cia Ventura, subrayaba <a href="https://mip.umh.es/blog/2022/02/08/retos-eticos-de-la-inteligencia-artificial-en-los-medios-de-comunicacion/">en un artÃ­culo en este blog</a>:</p>

<p>â€œSi el periodismo tiene que vigilar estos algoritmos o, mejor dicho, a quienes los gestionan, en coherencia deberÃ¡ estar en condiciones de usar la Inteligencia Artificial de forma Ã©tica, ponerla al servicio de su misiÃ³n de servicio pÃºblico, dotarla de sus valores y demostrar que es capaz de gestionarla como no lo hacen otros que se limitan a optimizarla con finalidades puramente comerciales y, por lo tanto, sin valoresâ€.</p>

<p>A medida que aumenta el nÃºmero de medios que recurren a la IA es necesario repensar la Ã©tica y la calidad del periodismo computacional y de todo lo que implica en los procesos de captaciÃ³n, producciÃ³n, ediciÃ³n y distribuciÃ³n de informaciones. EstÃ¡ claro que las empresas periodÃ­sticas deben plantearse importantes cuestiones Ã©ticas derivadas del uso de la IA y saldrÃ¡n perdiendo si no lo hacen desde ya. En este Ã¡mbito hay muchas zonas grises y amplio margen para el contraste de posturas, por lo que asistimos a un proceso complejo de toma de decisiones que debe incluir la perspectiva Ã©tica. Â¿QuÃ© problemas crean los sistemas automatizados? Â¿QuÃ© situaciones deben preocuparnos?</p>

<p><img src="/blog/images/shots/pexels-tara-winstead-8386440.jpg" alt="" />
<sup>Tara Winstead (Pexels)</sup></p>

<p>Hemos elaborado un listado de preguntas orientativas sobre las implicaciones Ã©ticas del periodismo automatizado. Se basa en <a href="https://ethicaljournalismnetwork.org/ethical-checklist-robot-journalism">las aportaciones de Thomas Kent</a>, veterano editor de la agencia Associated Press y asesor de la Red de Periodismo Ã‰tico, y en las <a href="https://textualvisualmedia.com/index.php/txtvmedia/article/view/301">conversaciones con profesionales de medios espaÃ±oles que han implementado algÃºn tipo de IA</a>, mantenidas junto con los colegas Alicia de Lara y FÃ©lix Arias. Lo dividimos en cuatro fases del proceso productivo: PreproducciÃ³n; ProducciÃ³n; ValoraciÃ³n informativa, y Cuestiones a posteriori.</p>

<h3 id="1-preproducciÃ³n">1. PreproducciÃ³n</h3>

<ul>
  <li>&lt;!â€“\[if !supportLists]â€“Â¿CuÃ¡l es la precisiÃ³n de los datos subyacentes? Los datos que utiliza la herramienta, Â¿proceden de fuentes de informaciÃ³n contrastada como empresas, bolsas, administraciones o instituciones pÃºblicas? Si los datos no proceden de fuentes autorizadas, Â¿cÃ³mo puedes asegurarte de que son fiables?</li>
</ul>

<!--\[if !supportLists]-->
<p>Â·Â Â Â Â Â Â  <!--\[endif]-->Â¿CuÃ¡l es la precisiÃ³n de los datos subyacentes? Los datos que utiliza la herramienta, Â¿proceden de fuentes de informaciÃ³n contrastada como empresas, bolsas, administraciones o instituciones pÃºblicas? Si los datos no proceden de fuentes autorizadas, Â¿cÃ³mo puedes asegurarte de que son fiables?</p>

<!--\[if !supportLists]-->
<p>Â·Â Â Â Â Â Â  <!--\[endif]-->Â¿Tienes los derechos sobre los datos? Â¿Tiene el proveedor de los datos derecho legal a enviÃ¡rtelos? Â¿Cuentas con permiso para publicarlos? Los lectores considerarÃ¡n al medio responsable de los datos, sea cual sea la fuente original.</p>

<p><!--EndFragment--></p>
<ul>
  <li>+Â¿Tienes los derechos sobre los datos? Â¿Tiene el proveedor de los datos derecho legal a enviÃ¡rtelos? Â¿Cuentas con permiso para publicarlos? Los lectores considerarÃ¡n al medio responsable de los datos, sea cual sea la fuente original.</li>
  <li>
    <!--\\[if !supportLists]-->
    <p>Â·Â Â Â Â Â Â  <!--\\[endif]-->Algunos sistemas automatizados crean presentaciones de vÃ­deo o fotos para acompaÃ±ar los textos. Â¿Puedes estar seguro de que el sistema accede sÃ³lo a las imÃ¡genes para cuyo uso tiene derecho legal? Â¿CÃ³mo asegurarse de que no utiliza imÃ¡genes hirientes o de mal gusto?</p>
  </li>
  <li>
    <!--\\[if !supportLists]-->
    <p>Â·Â Â Â Â Â Â  <!--\\[endif]-->Â¿QuÃ© medidas de seguridad puedes adoptar para comprobar la veracidad, exactitud y sesgos de los contenidos generados por IA, antes de su publicaciÃ³n?</p>
  </li>
</ul>

<h3 id="2-producciÃ³n"><strong>2. ProducciÃ³n</strong></h3>

<ul>
  <li>
    <!--\\[if !supportLists]-->
    <p>Â·Â Â Â Â Â Â  <!--\\[endif]-->Â¿QuÃ© datos destacarÃ¡ el sistema de IA? Por ejemplo, en una noticia que resuma el dÃ­a en los mercados, Â¿con quÃ© valores e Ã­ndices empezarÃ¡ la herramienta? Â¿CompararÃ¡ las Ãºltimas cifras con las de principios de aÃ±o o con las de hace cinco aÃ±os?</p>
  </li>
  <li>
    <!--\\[if !supportLists]-->
    <p>Â·Â Â Â Â Â Â  <!--\\[endif]-->Â¿QuiÃ©n y cÃ³mo se supervisa la herramienta? Los errores con los datos subyacentes o el software de automatizaciÃ³n pueden generar fallos rÃ¡pidamente. Comprueba el sistema de automatizaciÃ³n: que un editor revise cada pieza antes de publicarla.</p>
  </li>
  <li>
    <!--\\[if !supportLists]-->
    <p>Â·Â Â Â Â Â Â  <!--\\[endif]-->Â¿Los informes automatizados coinciden con el estilo habitual en la publicaciÃ³n? La ortografÃ­a y el estilo de redacciÃ³n deben coincidir con el resto del medio. Los lectores se sentirÃ¡n confundidos por un contenido que desentone con su estilo periodÃ­stico.</p>
  </li>
  <li>
    <!--\\[if !supportLists]-->
    <p>Â·Â Â Â Â Â Â  <!--\\[endif]-->Â¿QuÃ© pasa con el mantenimiento a largo plazo? Las redacciones deben mantener regularmente sus equipos de IA y supervisar el trabajo de los algoritmos.</p>
  </li>
</ul>

<p><img src="/blog/images/shots/pexels-andrea-piacquadio-3768911.jpg" alt="" />
<sup>Andrea Piacquadio (Pexels)</sup></p>

<h3 id="3-valoraciÃ³n-informativa"><strong>3. ValoraciÃ³n informativa</strong></h3>

<ul>
  <li>
    <!--\\[if !supportLists]-->
    <p>Â·Â Â Â Â Â Â  <!--\\[endif]-->Â¿Es el tema apropiado para la automatizaciÃ³n?</p>
  </li>
  <li>
    <!--\\[if !supportLists]-->
    <p>Â·Â Â Â Â Â Â  <!--\\[endif]-->Â¿La cobertura de quÃ© temas vas a automatizar? Antes de â€œenchufarâ€ una fuente de datos, piensa es deseable que todo fluya automÃ¡ticamente, sin apenas supervisiÃ³n.</p>
  </li>
  <li>
    <!--\\[if !supportLists]-->
    <p>Â·Â Â Â Â Â Â  <!--\\[endif]-->Â¿RevelarÃ¡s que estÃ¡s usando la IA? Â¿SerÃ¡s transparente en todo el proceso?</p>
  </li>
  <li>
    <!--\\[if !supportLists]-->
    <p>Â·Â Â Â Â Â Â  <!--\\[endif]-->Â¿UsarÃ¡s algoritmos que puedan distorsionar intencionadamente la cobertura y, en caso afirmativo, lo revelarÃ­as?</p>
  </li>
  <li>
    <!--\\[if !supportLists]-->
    <p>Â·Â Â Â Â Â Â  <!--\\[endif]-->Â¿Vas a reducir el personal humano? Muchos medios que usan la automatizaciÃ³n afirman que su objetivo no es sustituir a los periodistas por robots, sino permitir que su personal se centre en la informaciÃ³n relevante y evite las tareas rutinarias. Pero si se contratan menos periodistas porque hay que invertir en IA, surge un problema.</p>
  </li>
</ul>

<h3 id="4-cuestiones-a-posteriori"><strong>4. Cuestiones a posteriori</strong></h3>

<ul>
  <li>
    <!--\\[if !supportLists]-->
    <p>Â·Â Â Â Â Â Â  <!--\\[endif]-->Â¿El sistema registra todos los pasos utilizados para crear cada pieza?</p>
  </li>
  <li>
    <!--\\[if !supportLists]-->
    <p>Â·Â Â Â Â Â Â  <!--\\[endif]-->Si alguien cuestiona la veracidad de una pieza generada mediante IA, Â¿puedes dar una explicaciÃ³n u obtener una respuesta de los proveedores de datos y de automatizaciÃ³n? Â Â¿Puedes defender cÃ³mo se elaborÃ³ cada pieza?</p>
  </li>
  <li>
    <!--\\[if !supportLists]-->
    <p>Â·Â Â Â Â Â Â  <!--\\[endif]-->Â¿Tienes los procesos automatizados lo suficientemente bien documentados como para que, incluso cuando cambie el personal humano o la plantilla del algoritmo, poder explicar cÃ³mo se gestionÃ³ cada pieza?</p>
  </li>
  <li>
    <!--\\[if !supportLists]-->
    <p>Â·Â Â Â Â Â Â  <!--\\[endif]-->Â¿Y si te demandan? Imagina a las partes de un proceso judicial exigiendo el cÃ³digo fuente de la automatizaciÃ³n. Â¿Lo revelarÃ¡s o lo defenderÃ¡s como secreto profesional?</p>
  </li>
</ul>

<p>Las implicaciones Ã©ticas de la IA en las redacciones presentan un componente multidisciplinar, fruto de su complejidad, por lo que conviene sopesar las diferentes perspectivas. Esta complejidad puede contribuir a generar tensiones, por ejemplo, entre el departamento comercial y el editorial, entre el equipo tÃ©cnico y el periodÃ­stico, entre los medios y los usuarios. Al mismo tiempo, <strong>surgen zonas grises</strong> donde los criterios Ã©ticos no parecen claros y abundan los matices, precisamente por la naturaleza compleja del fenÃ³meno.</p>

<p>La Ã©tica en el uso de la IA puede convertirse en un valor estratÃ©gico para las empresas de comunicaciÃ³n, que contribuya a superar la crisis generada por la incertidumbre sobre el modelo de negocio, la pÃ©rdida de confianza por parte de los lectores o el incremento de la desinformaciÃ³n.Â <a href="https://mip.umh.es/blog/2021/05/18/etica-innovacion-periodistica-valores/">Como apuntaba en este blog</a>, debemos tener en cuenta la Ã©tica de los fines (Â¿Para quÃ© lo hago?), de los procedimientos (Â¿CÃ³mo lo hago?) y de los valores (por quÃ© lo hago).Â <strong>Porque no cabe un periodismo innovador que no sea Ã©tico, nos jugamos el futuro de la profesiÃ³n si no actuamos con transparencia y responsabilidad.</strong></p>
:ET