I"Í4<p>Ver es creer. Las grabaciones de v√≠deo permiten que cualquiera se convierta en testigo de primera mano de un evento, lo que le ahorra la necesidad de decidir si confiar en el testimonio de otra persona. Gracias a los tel√©fonos inteligentes y a las redes sociales, que permiten compartir y consumir esas grabaciones de forma masiva, las personas pueden confiar en sus propios ojos y o√≠dos como si fueran notarios de la realidad. Sin embargo, en un mundo de mentiras cada vez m√°s sofisticadas, ver ya no es creer. Los <em>deepfakes</em>, v√≠deos fabricados mediante modelos de Inteligencia Artificial, pretenden generar pol√©mica y manipular a la opini√≥n p√∫blica. Y ya hay varios medios que trabajan para combatirlos.</p>

<p>Por el momento, en su mayor√≠a son v√≠deos sat√≠ricos y f√°cilmente detectables. Tras las elecciones del 10-N, se difundi√≥ en las redes <a href="https://www.youtube.com/watch?v=dj5M4s-cdAw">un v√≠deo</a> con <em>fakes</em> de los cinco principales candidatos caracterizados como protagonistas del Equipo E, <strong>una parodia del Equipo A que super√≥ el mill√≥n de reproducciones en apenas 48 horas</strong>. Los ejemplos de <em>deepfakes</em> sat√≠ricos incluyen <a href="https://www.youtube.com/watch?v=5hZOcmqWKzY">los intercambios de caras</a> entre el presidente Donald Trump y la canciller alemana Angela Merkel; entre el presidente argentino <a href="https://www.youtube.com/watch?v=M8t6hGRtDac">Mauricio Macri y Adolf Hitler</a>; y la falsificaci√≥n de <a href="https://www.youtube.com/watch?v=gLoI9hAX9dw">unas declaraciones de Barak Obama</a>. Seg√∫n un estudio de la consultora <strong>Deeptrace</strong>, en la red <strong>actualmente circulan al menos 15.000 <em>deepfakes</em> de todo tipo</strong>.</p>

<p><img src="/blog/images/shots/1-deepfake-video.jpg" alt="" /></p>

<p>Pero el asunto se vuelve m√°s serio cuando se busca manipular a la opini√≥n p√∫blica con <em>deepfakes</em> que generan pol√©mica, enga√±an e indignan a las masas. Imagina un v√≠deo que muestre al presidente Nicol√°s Maduro en una conversaci√≥n privada con otro mandatario, en la que aparentemente revela un plan para llevar a cabo varios asesinatos pol√≠ticos en Venezuela. O un clip de audio en el que dos generales norteamericanos dise√±an una operaci√≥n encubierta para matar a varios l√≠deres palestinos radicales en el estrecho de Gaza. O un v√≠deo en el que se vea a un conocido pol√≠tico independentista catal√°n quemando una foto de Felipe VI. <strong>Se trata de grabaciones que tendr√≠an un enorme potencial de agitaci√≥n social, con consecuencias incalculables</strong>. Por ello, <a href="https://edition.cnn.com/interactive/2019/01/business/pentagons-race-against-deepfakes/">el Pent√°gono norteamericano ya ha creado un programa para combatirlas</a>.</p>

<p>El <em>deepfake</em> es una t√©cnica de inteligencia artificial que permite editar v√≠deos falsos que aparentemente parecen reales, utilizando algoritmos de aprendizaje no supervisados, conocidos como RGAs (Red Generativa Antag√≥nica), a partir de grabaciones ya existentes. Este tipo de contenidos actualmente pueden elaborarse utilizando herramientas al alcance de cualquiera que disponga de un ordenador, acceso a internet y a una base de datos con im√°genes de calidad. Las falsificaciones resultantes son tan convincentes que resulta imposible distinguirlas de las reales.</p>

<p>Los <em>deepfakes</em> no se limitan a situaciones en las que el v√≠deo o el audio de eventos o declaraciones inexistentes tengan la apariencia de verdad. Imagina, por ejemplo, que una pieza con el estilo y el dise√±o de una noticia publicada en un medio se distribuye en las redes sociales y, al hacerlo, difunde un contenido falso como si fuera de ese medio. La pieza podr√≠a compartirse porque tiene la apariencia de un art√≠culo publicado en el El Pa√≠s o el El Confidencial, por ejemplo, sin que ninguno de estos medios tuviera nada que ver. La falsedad no solo est√° en el contenido, sino <strong>en la forma en que la pieza se disfraza como proveniente de una fuente period√≠stica autorizada</strong>.</p>

<p><img src="/blog/images/shots/2gif-obama.gif" alt="" /></p>

<p>La preocupaci√≥n ante este problema aumenta en todo el mundo. El aumento de los v√≠deos ultrafalsos amenaza la erosi√≥n de las defensas institucionales contra la desinformaci√≥n en el √°mbito digital y plantea graves riesgos para la democracia y la seguridad. La sociedad ya afronta graves problemas de desinformaci√≥n y la distorsi√≥n de la verdad empeora a medida que los ciudadanos interact√∫an de manera t√≥xica, derivada de los sesgos cognitivos. Los  <em>deepfakes</em> incrementar√°n la gravedad de este problema; <strong>los individuos y las empresas se enfrentar√°n a t√©cnicas muy sofisticadas de explotaci√≥n, intimidaci√≥n y enga√±o</strong>. Sin embargo, a√∫n queda mucho por investigar sobre los riesgos que afrontan los ciudadanos, las instituciones y la sociedad ante la actuaci√≥n maliciosa de quienes emplean esta tecnolog√≠a.</p>

<p>El problema no es solo que se utilicen para avivar las divisiones sociales e ideol√≥gicas. Tambi√©n pueden convertirse en una coartada para los mentirosos: conforme la sociedad se vuelve m√°s consciente de la existencia de <em>deepfakes</em>, los personajes p√∫blicos que aparecen en las grabaciones aut√©nticas que muestran un comportamiento inapropiado podr√°n negar la veracidad de esos v√≠deos. Adem√°s, a medida que los ciudadanos se sensibilizan ante la amenaza de los  <em>deepfakes</em>, tender√°n a confiar menos en los medios y en las informaciones que les llegan. Por su parte, <strong>los periodistas tendr√°n que actuar con mayor cautela al publicar audios o v√≠deos sobre acontecimientos de √∫ltima hora</strong>, tales como manifestaciones o atentados, por temor a que las im√°genes hayan sido falsificadas.</p>

<p>Aunque el trabajo de verificar una informaci√≥n mediante el contraste de m√∫ltiples fuentes es algo b√°sico en el periodismo, las t√©cnicas se han vuelto m√°s complejas a medida que se disponen de nuevas herramientas de verificaci√≥n digital. Los periodistas <em>fact-checkers</em> <strong>trabajan como aut√©nticos ‚Äúdetectives digitales‚Äù para luchar contra los <em>deepfakes</em> y las im√°genes falsificadas.</strong> Veamos algunos casos:</p>

<ul>
  <li>Los profesionales de <strong>The New York Times</strong> utilizaron t√©cnicas de trabajo ‚Äúforense‚Äù para confirmar la fecha, la hora y la ubicaci√≥n <a href="https://www.nytimes.com/2017/05/01/insider/the-times-uses-forensic-mapping-to-verify-a-syrian-chemical-attack.html?_r=0">de un ataque con armas qu√≠micas en Siria</a> mediante el an√°lisis de informaci√≥n de Google Earth, videos de aficionados, cuentas de testigos oculares y una aplicaci√≥n de movimiento solar, SunCalc. La informaci√≥n resultante desacredit√≥ las afirmaciones de los l√≠deres pol√≠ticos rusos y sirios. El equipo de investigaciones visuales del peri√≥dico utiliz√≥ t√°cticas similares para construir una l√≠nea de tiempo de v√≠deo detallada de la masacre provocada por un tiroteo en Las Vegas.</li>
  <li>Reporteros de <strong>ProPublica</strong> y <strong>Frontline</strong> <a href="https://www.propublica.org/article/michael-miselis-rise-above-movement-white-supremacist-group-northrop-grumman">investigaron horas de v√≠deo y miles de datos de publicaciones en redes sociales</a> para identificar a un miembro de un grupo violento de supremacistas blancos, que ten√≠a una autorizaci√≥n de seguridad nacional por su trabajo con un contratista de defensa. Un d√≠a despu√©s de la publicaci√≥n de la investigaci√≥n, el contratista Northrop Grumman despidi√≥ a ese empleado.</li>
  <li>En 2017, la <strong>BBC</strong> cre√≥ un equipo de verificaci√≥n, <a href="https://www.bbc.com/news/reality_check">Reality Check,</a> ante la ingente cantidad de material falso y  <em>deepfakes</em> que necesitaban comprobar. En septiembre de 2018, los periodistas lograron verificar mediante t√©cnicas de geolocalizaci√≥n, la procedencia de un v√≠deo<a href="https://www.poynter.org/fact-checking/2018/how-the-bbc-verified-that-video-of-a-grisly-murder-in-cameroon-step-by-step/"> que mostraba el asesinato de mujeres y ni√±os a manos de soldados en Camer√∫n</a>, y evidenciaron la veracidad de su contenido, frente al escepticismo de las autoridades del pa√≠s.</li>
  <li>En junio de 2019, la <strong>Unidad de Fact Checking</strong> del <strong>Washington Post</strong> public√≥ <a href="https://www.washingtonpost.com/graphics/2019/politics/fact-checker/manipulated-video-guide/">una excelente gu√≠a sobre c√≥mo detectar v√≠deos manipulados y <em>deepfakes</em></a>. Sus recomendaciones cubren tres grandes √°reas de manipulaci√≥n: falta de contexto, edici√≥n enga√±osa y transformaci√≥n maliciosa, y ofrecen valiosos consejos pr√°cticos.</li>
  <li><strong>The Wall Street Journal</strong> ha dado un paso decisivo con la creaci√≥n de <a href="https://www.niemanlab.org/2018/11/how-the-wall-street-journal-is-preparing-its-journalists-to-detect-deepfakes/">una unidad especializada en combatir <em>deepfakes</em></a> en noviembre de 2018. La unidad, liderada por <strong>Francesco Marconi</strong>, ha establecido un protocolo de trabajo que incluye la verificaci√≥n de las fuentes, la b√∫squeda de im√°genes previas, el an√°lisis de las grabaciones y la detecci√≥n de irregularidades tales como la asincron√≠a del audio, la alteraci√≥n del entorno o la modificaci√≥n digital. Precisamente <strong>est√°n incorporando herramientas de Inteligencia Artificial</strong> para detectar estos v√≠deos falsos.</li>
</ul>

<p><img src="/blog/images/shots/3-gif-deep-fakes.gif" alt="" /></p>

<p><a href="https://retina.elpais.com/retina/2018/09/17/innovacion/1537177382_367863.html">Como explica en el suplemento Retina <strong>Ra√∫l Arrabales</strong>,</a> experto en Inteligencia Artificial, los propios algoritmos de <em>deep learning</em> pueden usarse para detectar  <em>deepfakes</em> de forma autom√°tica e incluso para generar ‚Äúfalsificaciones de laboratorio‚Äù que sirvan de entrenamiento para detectores de v√≠deos, im√°genes y documentos falsos. De esta forma se podr√°n bloquear dichos contenidos o, al menos, advertir al consumidor de que est√° viendo un v√≠deo generado por ordenador. Para crear <em>deepfakes</em> de momento <strong>hace falta disponer de un amplio volumen de material previo sobre la persona objeto de la manipulaci√≥n</strong>. Por eso se han fabricado sobre pol√≠ticos como Obama o Trump, porque existe un archivo inmenso de grabaciones de sus discursos que facilita la tarea.</p>

<p>Sin embargo, <a href="https://www.xataka.com/inteligencia-artificial/ha-comenzado-carrera-para-crear-tecnologia-capaz-detectar-deepfakes-falsificadores-llevan-ventaja">los algoritmos de detecci√≥n de  <em>deepfakes</em> siguen yendo por detr√°s de la tecnolog√≠a usada para generarlos</a>. Los actores malintencionados act√∫an mucho m√°s r√°pidamente que quienes buscan detenerlos, de modo que los  <em>deepfakes</em> resultan cada vez m√°s dif√≠ciles de detectar. En <strong>Silicon Valley</strong>, <a href="https://www.latimes.com/politics/story/2019-11-05/deep-fakes-2020-election-silicon-valley-cure">varias tecnol√≥gicas llevan tiempo trabajando</a> para contrarrestar los efectos perversos de estas herramientas. Por su parte, <a href="https://elpais.com/tecnologia/2019/10/29/actualidad/1572343240_676009.html"><strong>Google y Facebook</strong> ya han creado una base de datos </a>con miles de archivos audiovisuales manipulados para entrenar a las herramientas de detecci√≥n autom√°tica.</p>

<p><img src="/blog/images/shots/4-deep-fakes-zukeberg.jpeg" alt="" /></p>

<p>Numerosos expertos reivindican la necesidad de <strong>implantar un programa intensivo de alfabetizaci√≥n medi√°tica desde la educaci√≥n secundaria que aborde estas cuestiones.</strong> Algunas iniciativas, como <a href="https://es.unesco.org/sites/default/files/journalism_fake_news_disinformation_print_friendly_0.pdf">este manual sobre ‚ÄúPeriodismo, noticias falsas y desinfomaci√≥n‚Äù </a>publicado por la <strong>UNESCO</strong>, contienen directrices muy √∫tiles para verificar contenidos y luchar contra la desinformaci√≥n. El manual propone cuestiones b√°sicas, como:</p>

<p>- ¬øHay fallos e inconsistencias en el v√≠deo o en el audio?</p>

<p>- ¬øConf√≠as en la fuente?</p>

<p>- ¬øPuedes encontrar otras im√°genes que corroboren el contenido del v√≠deo?</p>

<p>- ¬øPuedes comprobar la ubicaci√≥n geogr√°fica, la fecha de grabaci√≥n, la geolocalizaci√≥n y otro tipo de metadatos?</p>

<p>Nuestra experiencia sobre lo que sucede en el mundo y nuestra capacidad para tomar decisiones al respecto depende de que la informaci√≥n a la que accedemos sea veraz. Cuando se vuelven virales contenidos falsos que se hacen pasar por aut√©nticos, <strong>el riesgo de manipulaci√≥n es muy elevado, con consecuencias perversas en la opini√≥n p√∫blica</strong>. Un problema que plantean los  <em>deepfakes</em> y otras t√©cnicas sofisticadas de desinformaci√≥n es de qu√© modo los legisladores y las instituciones pueden preservar el derecho a la informaci√≥n veraz y restringir las t√©cnicas de manipulaci√≥n de contenidos sin entrar en conflicto con la libertad de expresi√≥n y sin ejercer un control contraproducente en internet. Medios y periodistas comparten la responsabilidad de combatir la desinformaci√≥n generada por estos v√≠deos cada vez mejor elaborados, <strong>con objeto de salvaguardar la calidad del debate en las sociedades democr√°ticas</strong>.</p>
:ET