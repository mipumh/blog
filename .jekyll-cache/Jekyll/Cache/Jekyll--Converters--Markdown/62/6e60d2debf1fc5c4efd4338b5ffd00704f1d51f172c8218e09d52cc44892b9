I""B<p>Acaba de publicarse el informe ‘Algoritmos en las redacciones: retos y recomendaciones para dotar a la Inteligencia Artificial de los valores éticos del periodismo’ del <a href="https://fcic.periodistes.cat/"></a> <a href="https://fcic.periodistes.cat/">Consell de la Informació de Catalunya</a>. Se trata de un estudio que tiene como finalidad dotar al periodismo de herramientas para convertirse en referente de la tecnoética de la comunicación. En este artículo analizamos las claves del informe, que ofrece una reflexión crítica sobre la gestión algorítmica de la información por parte de los medios.</p>

<p><img src="/blog/images/shots/foto1_ai-technology-brain-background-digital-transformation-concept-1-.jpeg" alt="" /></p>

<p>Desde que surgieron los algoritmos y hasta su consolidación, muchos sintieron optimismo ante la expectativa de una esfera pública renovada en la que más voces serían escuchadas. Incluso se les llegó a <a href="https://elpais.com/diario/2011/01/23/domingo/1295758353_850215.html">atribuir</a> un papel primordial en las revoluciones árabes o en el 15M en España, entre otros acontecimientos de orden mundial, por ofrecer la posibilidad de disponer de una plataforma de comunicación a cualquier persona o causa.</p>

<p>Sin embargo, conforme pasa el tiempo, comprobamos que con la IA no todo ha sido para mejor: ha contribuido a generar un modelo de negocio basado en una lógica extractivista de los datos personales que <a href="https://www.ted.com/talks/zeynep_tufekci_we_re_building_a_dystopia_just_to_make_people_click_on_ads?language=es">erosiona</a> la privacidad de la ciudadanía; la desinformación prolifera sin control en el ecosistema informativo y debilita nuestra visión comunitaria al facilitar el consumo hiperpersonalizado de la información que promueven sus algoritmos.</p>

<p>Es difícil saber si existe más desinformación en la actualidad o si estamos más aislados en burbujas que antes, cuando solo teníamos la opción de consumir medios tradicionales y nos comprábamos el diario, veíamos la TV o escuchábamos la radio que más sintonizaba con nuestras sensibilidades e ideales políticos. Muchos hemos dejado de ver con tanto optimismo el papel de las plataformas a consecuencia de estos efectos que hemos ido descubriendo con el tiempo.</p>

<p>En ningún caso creemos que nos encontremos ante un problema tecnológico. La Inteligencia Artificial es una herramienta y como tal sus efectos están condicionados al uso que le demos. El problema fundamental en la raíz de las consecuencias de la gestión algorítmica de la información está en la optimización de esta tecnología con el único propósito conseguir finalidades comerciales, sin tener en cuenta los valores éticos que podrían disminuir los indicadores de <em>performance</em> (resultados en base a métricas asociadas a objetivos puramente de negocio) por los que se guían, en términos generales, las grandes tecnológicas.</p>

<p><strong>La Inteligencia Artificial y el periodismo</strong></p>

<p>En este contexto consideramos que al periodismo le convendría adoptar una postura, no solo ante los efectos de la gestión computacional de la comunicación, sino también respecto a la creciente automatización en la sociedad, mediante decisiones algorítmicas cada vez más presentes en sectores tan determinantes como la salud, la justicia o la educación. Hoy los algoritmos <a href="https://eticasfoundation.org/es/oasi/">participan</a> en procesos como el diagnóstico médico, el <a href="https://algorithmwatch.org/en/riscanvi/">cálculo del índice de reincidencia de presos</a> y la concesión de ayudas sociales. El mismo Servicio Público de Empleo usa algoritmos para decidir quién tiene derecho al paro. La computación de cuestiones tan sensibles entraña riesgos derivados del uso de sistemas mal diseñados o de datos de calidad insuficiente que provocan sesgos algorítmicos, de falta de supervisión o de transparencia. Además, desde una perspectiva más amplia, cabe considerar que las promesas tecnológicas de productividad conllevan una deshumanización en los procesos a la que merece la pena estar atentos puesto que hasta ahora no ha dejado de crecer.</p>

<p> </p>

<p><img src="/blog/images/shots/ai-and-journalism.jpg" alt="" /></p>

<p> </p>

<p>Si el periodismo tiene que vigilar estos algoritmos o, mejor dicho, a quienes los gestionan, en coherencia deberá estar en condiciones de usar la Inteligencia Artificial de forma ética, ponerla al servicio de su misión de servicio público, dotarla de sus valores y demostrar que es capaz de gestionarla como no lo hacen otros que se limitan a optimizarla con finalidades puramente comerciales y, por lo tanto, sin valores.</p>

<p>En las redacciones ya le hacemos a la Inteligencia Artificial preguntas como: ¿Qué hecho es noticiable? ¿Qué titular elegir? ¿Qué forma debe tener el contenido? ¿Qué temas hay que destacar? Todas ellas forman parte del núcleo de la función editorial del periodismo. En la investigación que hemos elaborado para el informe con la participación de los principales medios de Cataluña hemos podido comprobar que la IA está ya presente en todas las fases de la cadena de valor.</p>

<p>La IA interviene desde la identificación de los temas noticiables, pasando por la recopilación de contenidos, el rastreo entre bases de datos propias y ajenas, la creación automatizada de noticias, las transcripciones de voz a texto, de texto a infografía o a vídeo o la generación automatizada de textos escritos. La automatización está muy presente también en la fase de distribución del contenido y se orienta tanto a las finalidades editoriales como a los objetivos de marketing.</p>

<p><strong>Elaboración del Informe del CIC</strong></p>

<p>Para abordar esta complejidad en momentos muy iniciales de esta integración de la IA a las rutinas productivas de los medios, optamos por identificar aquellas herramientas o prácticas que emplean IA que generan más preocupaciones éticas. Luego reflexionamos sobre los dilemas que genera cada tema clave y analizamos a qué valores de la ética periodística afecta. Finalmente, elaboramos un decálogo de recomendaciones para el uso ético de la Inteligencia Artificial en los medios de comunicación.</p>

<p>Para elaborar el informe contamos con un comité experto de primer nivel. También dispusimos de una amplia participación del sector, a través de una encuesta a profesionales de los medios de comunicación en todo el país. Además, contamos con la colaboración de los principales medios catalanes, en distintos grados: tanto a través de encuestas como en grupos de discusión, en los que tuvimos ocasión de confrontar las reflexiones teóricas con la práctica del día a día en los medios. Así, en el estudio abordamos los problemas a los que se enfrentan los medios en estos momentos iniciales de la adopción de esta tecnología.</p>

<p>Algunas de las principales preocupaciones que detectamos tienen que ver con el temor a la pérdida de calidad del producto informativo, a generar desinformación, sesgos algorítmicos, a contribuir a generar cámaras de eco y polarización o cuestiones relacionadas con la privacidad.</p>

<p> </p>

<p><img src="/blog/images/shots/nubedepalabras2-1-.jpeg" alt="" /></p>

<p>Una vez identificados los temas clave y los dilemas, analizamos a qué grandes principios de la ética periodística afectaba, siguiendo la misma metodología que el <a href="https://www.periodistes.cat/">Col·legi de Periodistes de Catalunya</a> usó en la actualización del <a href="https://www.periodistes.cat/codi-deontologic">código deontológico</a> en 2016 y que consistió en confrontar las nuevas prácticas con los valores fundamentales de la ética periodística -veracidad, justicia, libertad y responsabilidad- y confirmamos que las aplicaciones a priori más controvertidas colisionaban con todos ellos. Además, identificamos que algunos de los principios de la profesión que figuran en los códigos deontológicos adquieren más relevancia con la adopción de la IA. Estos son los principios de transparencia y de privacidad.</p>

<p>Tras examinar las encuestas, entrevistas y las reflexiones surgidas en los grupos de discusión, definimos siete temas clave en los que profundizar para luego elaborar las recomendaciones para el uso ético de la IA en los medios que revisó el comité experto en ética del CIC. Las cuestiones fundamentales que desarrolla el estudio son las siguientes:</p>

<p>●  Contenido automatizado con criterio editorial</p>

<p>●  Personalización que convive con la diversidad y promueve la salud de la esfera pública</p>

<p>●  Supervisión y calidad de los datos para evitar sesgos</p>

<p>●  Preservar la privacidad de los usuarios con responsabilidad</p>

<p>●  El periodismo de calidad pasa por poner en valor el factor humano</p>

<p>●  Financiación de las plataformas e independencia informativa</p>

<p>●  IA para fortalecer los valores del periodismo</p>

<p>El informe tiene un carácter divulgativo y está dirigido a un público no necesariamente especializado en tecnología. Ofrecemos un resumen de algunos temas clave.</p>

<p><strong>Contenido automatizado con criterio editorial</strong></p>

<p>Tanto la transparencia como la supervisión humana resultan fundamentales para evitar y mitigar posibles errores o sesgos en la generación automatizada de contenido. Antes, sin embargo, será necesario identificar qué tipo de automatización será imprescindible comunicar, puesto que ésta se utiliza en muchos procesos, y no es lo mismo emplearla para una transcripción de voz a texto que a la hora de generar todo el texto de una noticia. Seguramente será más relevante comunicar el segundo caso que el primero.</p>

<p>También en el contexto del contenido automatizado y en línea con la legislación europea, resultará fundamental dejar muy claro al usuario que está hablando con una máquina en el uso de bots informativos. El principio de transparencia, que ya estaba presente en el código deontológico, se resignifica y adquiere gran protagonismo con la llegada de la IA a las redacciones. </p>

<p>Además de afirmar el compromiso periodístico con la verdad, la transparencia constituye la protección más eficiente ante posibles errores. La explicabilidad y evidencia de dónde sale cualquier tipo de información para actuar de forma responsable.</p>

<p> </p>

<p><img src="/blog/images/shots/foto_3alexa-steinbrück-_-better-images-of-ai-_-explainable-ai-_-cc-by-4.0-1-.jpeg" alt="" /></p>

<p>Alexa Steinbrück / Better Images of AI / Explainable AI / CC-BY 4.0</p>

<p><strong>Personalización que convive con la diversidad y promueve la salud de la esfera pública</strong></p>

<p>La personalización es una gran herramienta a la hora de mejorar la experiencia del usuario. Sin embargo, conviene considerar ciertos aspectos a la hora de incorporar su uso en el contexto del periodismo. Si el medio personaliza hasta el extremo puede acabar desnaturalizándose, puesto que en la misión del periodismo está incentivar la visión comunitaria sobre las cuestiones de interés público. Aquí también, la supervisión de los sistemas en todas sus fases de creación e implementación resultará fundamental para evitar sesgos que podrían excluir a grupos minoritarios.</p>

<p>Otras cuestiones susceptibles de colisionar con los principios éticos del periodismo y además con la <a href="https://eur-lex.europa.eu/legal-content/ES/TXT/?uri=celex:52021PC0206">legislación que prepara la UE</a>, son los sistemas que pueden llegar a manipular el comportamiento de las personas a través del diseño persuasivo que a menudo usan motores de recomendación en otras plataformas. Habrá que prestar especial atención cuando estos sistemas puedan ser utilizados por personas con vulnerabilidades psicológicas o menores de edad.</p>

<p><strong>Supervisión y calidad de los datos para evitar sesgos</strong></p>

<p>Una de las mayores preocupaciones sobre los riesgos de la IA en cualquier ámbito, incluido el de la comunicación, son los sesgos que pueden contener los resultados de los procesos para los que se ha optimizado.</p>

<p>No hay automatización sin datos, y para que estos sesgos no se produzcan será imprescindible entrenar a los sistemas con datos representativos del problema que se quiere solucionar, es decir, convendrá garantizar que el algoritmo disponga de la información necesaria para ejecutar los procedimientos para las finalidades que se ha optimizado.  En este punto se hace de nuevo necesario apelar a la transparencia, y estar en condiciones de poder explicar, antes o a posteriori, por qué nuestro sistema ha tomado una determinada determinación. En el estudio del CIC damos cuenta de potenciales sesgos en algoritmos en el contexto del periodismo.</p>

<p><img src="/blog/images/shots/foto2_anton-grabolle-_-better-images-of-ai-_-human-ai-collaboration-_-cc-by-4.0-1-.jpeg" alt="" /></p>

<p> </p>

<p>Anton Grabolle / Better Images of AI / Human-AI collaboration / CC-BY 4.0</p>

<p> </p>

<p><strong>Preservar la privacidad de los usuarios con responsabilidad</strong></p>

<p>El periodismo deberá tomar posición respecto al problema de erosión de la privacidad que se está convirtiendo en una amenaza para las libertades de la ciudadanía y que ha sido causado precisamente por el extractivismo de los datos personales que han originado las plataformas de comunicación algorítmica. </p>

<p>El marco legal del que disponemos en la UE resulta la herramienta más adecuada a la hora de establecer las mejores prácticas respecto al tratamiento de datos personales de los usuarios de los medios de comunicación. En concreto, el Reglamento General de Protección de Datos (RGPD) impone obligaciones directas. Según esta normativa europea, una empresa puede tratar datos personales en condiciones de justicia transparencia tener una finalidad especificada y legítima y limitarse a los datos necesarios para cumplir con la mencionada finalidad.</p>

<p>Conviene reflexionar sobre cómo se comunica desde los medios a los usuarios el uso de sus datos personales. En este caso, la transparencia pasa por el cómo, que en este caso supone huir de las comunicaciones mediante clausulados y letras pequeñas. Aprovechar la fortaleza de la que disponen los medios para expresar de una forma breve, clara y didáctica la clase de tratamiento de los datos de los usuarios y así promover su confianza.</p>

<p><strong>La calidad del periodismo pasa por poner en valor el factor humano</strong></p>

<p>Tal como decíamos más arriba, una de las principales preocupaciones del sector respecto a la adopción de la IA en los medios de comunicación es que se produzca una eventual pérdida de calidad del producto informativo. Esta percepción, que identificamos claramente entre el sector, contradice un discurso predominante que augura que la productividad que comportará la automatización resultará en tiempo disponible para que los periodistas puedan dedicarse a tareas más creativas o que aporten más valor.</p>

<p>En este punto los medios deberán tomar decisiones que implicarán reorganizar procesos y tareas y para que estos cambios repercutan en el producto de una forma cualitativa será necesario mantener un buen equilibrio ahorro-inversión que considere cómo la eficiencia que puede proporcionar la automatización da lugar a un producto de calidad, un factor determinante para conseguir objetivos comerciales.</p>

<p>Para conseguir extraer lo mejor de la IA, sin embargo, en los medios deberá existir una apuesta clara por la innovación e invertir recursos en la experimentación. Es necesario que el periodismo establezca unas bases sólidas que se puedan escalar y sean sostenibles en el futuro, tal como dijo la responsable de iniciativas estratégicas con IA del grupo Schibsted en <a href="https://www.patriciaventura.me/single-post/el-futuro-de-la-inteligencia-artificial-en-el-periodismo-pasa-por-construir-confianza"></a> <a href="https://www.patriciaventura.me/single-post/el-futuro-de-la-inteligencia-artificial-en-el-periodismo-pasa-por-construir-confianza">una de las sesiones del congreso</a> <a href="https://www.journalismaifestival.com/"> JournalismAI festival</a>. </p>

<p>En definitiva, integrar la IA en los medios que apuestan por la calidad informativa pasa por gobernarla e implica ponerla al servicio de la verdad, la justicia, la libertad y responsabilidad, los valores fundamentales que rigen la profesión periodística.</p>

<p><strong><a href="https://www.patriciaventura.me/single-post/presentaci%C3%B3n-del-informe-sobre-inteligencia-artificial-%C3%A9tica-y-periodismo">En este enlace</a> puedes descargarte el informe completo.</strong></p>
:ET