I"5<p>Ver es creer. Las grabaciones de vídeo permiten que cualquiera se convierta en testigo de primera mano de un evento, lo que le ahorra la necesidad de decidir si confiar en el testimonio de otra persona. Gracias a los teléfonos inteligentes y a las redes sociales, que permiten compartir y consumir esas grabaciones de forma masiva, las personas pueden confiar en sus propios ojos y oídos como si fueran notarios de la realidad. Sin embargo, en un mundo de mentiras cada vez más sofisticadas, ver ya no es creer. Los <em>deepfakes</em>, vídeos fabricados mediante modelos de Inteligencia Artificial, pretenden generar polémica y manipular a la opinión pública. Y ya hay varios medios que trabajan para combatirlos.</p>

<p>Por el momento, en su mayoría son vídeos satíricos y fácilmente detectables. Tras las elecciones del 10-N, se difundió en las redes <a href="https://www.youtube.com/watch?v=dj5M4s-cdAw">un vídeo</a> con <em>fakes</em> de los cinco principales candidatos caracterizados como protagonistas del Equipo E, <strong>una parodia del Equipo A que superó el millón de reproducciones en apenas 48 horas</strong>. Los ejemplos de <em>deepfakes</em> satíricos incluyen <a href="https://www.youtube.com/watch?v=5hZOcmqWKzY">los intercambios de caras</a> entre el presidente Donald Trump y la canciller alemana Angela Merkel; entre el presidente argentino <a href="https://www.youtube.com/watch?v=M8t6hGRtDac">Mauricio Macri y Adolf Hitler</a>; y la falsificación de <a href="https://www.youtube.com/watch?v=gLoI9hAX9dw">unas declaraciones de Barak Obama</a>. Según un estudio de la consultora <strong>Deeptrace</strong>, en la red <strong>actualmente circulan al menos 15.000 <em>deepfakes</em> de todo tipo</strong>.</p>

<p><img src="{{ site.baseurl }}/images/shots/1-deepfake-video.jpg" alt="" /></p>

<p>Pero el asunto se vuelve más serio cuando se busca manipular a la opinión pública con <em>deepfakes</em> que generan polémica, engañan e indignan a las masas. Imagina un vídeo que muestre al presidente Nicolás Maduro en una conversación privada con otro mandatario, en la que aparentemente revela un plan para llevar a cabo varios asesinatos políticos en Venezuela. O un clip de audio en el que dos generales norteamericanos diseñan una operación encubierta para matar a varios líderes palestinos radicales en el estrecho de Gaza. O un vídeo en el que se vea a un conocido político independentista catalán quemando una foto de Felipe VI. <strong>Se trata de grabaciones que tendrían un enorme potencial de agitación social, con consecuencias incalculables</strong>. Por ello, <a href="https://edition.cnn.com/interactive/2019/01/business/pentagons-race-against-deepfakes/">el Pentágono norteamericano ya ha creado un programa para combatirlas</a>.</p>

<p>El <em>deepfake</em> es una técnica de inteligencia artificial que permite editar vídeos falsos que aparentemente parecen reales, utilizando algoritmos de aprendizaje no supervisados, conocidos como RGAs (Red Generativa Antagónica), a partir de grabaciones ya existentes. Este tipo de contenidos actualmente pueden elaborarse utilizando herramientas al alcance de cualquiera que disponga de un ordenador, acceso a internet y a una base de datos con imágenes de calidad. Las falsificaciones resultantes son tan convincentes que resulta imposible distinguirlas de las reales.</p>

<p>Los <em>deepfakes</em> no se limitan a situaciones en las que el vídeo o el audio de eventos o declaraciones inexistentes tengan la apariencia de verdad. Imagina, por ejemplo, que una pieza con el estilo y el diseño de una noticia publicada en un medio se distribuye en las redes sociales y, al hacerlo, difunde un contenido falso como si fuera de ese medio. La pieza podría compartirse porque tiene la apariencia de un artículo publicado en el El País o el El Confidencial, por ejemplo, sin que ninguno de estos medios tuviera nada que ver. La falsedad no solo está en el contenido, sino <strong>en la forma en que la pieza se disfraza como proveniente de una fuente periodística autorizada</strong>.</p>

<p><img src="{{ site.baseurl }}/images/shots/2gif-obama.gif" alt="" /></p>

<p>La preocupación ante este problema aumenta en todo el mundo. El aumento de los vídeos ultrafalsos amenaza la erosión de las defensas institucionales contra la desinformación en el ámbito digital y plantea graves riesgos para la democracia y la seguridad. La sociedad ya afronta graves problemas de desinformación y la distorsión de la verdad empeora a medida que los ciudadanos interactúan de manera tóxica, derivada de los sesgos cognitivos. Los  <em>deepfakes</em> incrementarán la gravedad de este problema; <strong>los individuos y las empresas se enfrentarán a técnicas muy sofisticadas de explotación, intimidación y engaño</strong>. Sin embargo, aún queda mucho por investigar sobre los riesgos que afrontan los ciudadanos, las instituciones y la sociedad ante la actuación maliciosa de quienes emplean esta tecnología.</p>

<p>El problema no es solo que se utilicen para avivar las divisiones sociales e ideológicas. También pueden convertirse en una coartada para los mentirosos: conforme la sociedad se vuelve más consciente de la existencia de <em>deepfakes</em>, los personajes públicos que aparecen en las grabaciones auténticas que muestran un comportamiento inapropiado podrán negar la veracidad de esos vídeos. Además, a medida que los ciudadanos se sensibilizan ante la amenaza de los  <em>deepfakes</em>, tenderán a confiar menos en los medios y en las informaciones que les llegan. Por su parte, <strong>los periodistas tendrán que actuar con mayor cautela al publicar audios o vídeos sobre acontecimientos de última hora</strong>, tales como manifestaciones o atentados, por temor a que las imágenes hayan sido falsificadas.</p>

<p>Aunque el trabajo de verificar una información mediante el contraste de múltiples fuentes es algo básico en el periodismo, las técnicas se han vuelto más complejas a medida que se disponen de nuevas herramientas de verificación digital. Los periodistas <em>fact-checkers</em> <strong>trabajan como auténticos “detectives digitales” para luchar contra los <em>deepfakes</em> y las imágenes falsificadas.</strong> Veamos algunos casos:</p>

<ul>
  <li>Los profesionales de <strong>The New York Times</strong> utilizaron técnicas de trabajo “forense” para confirmar la fecha, la hora y la ubicación <a href="https://www.nytimes.com/2017/05/01/insider/the-times-uses-forensic-mapping-to-verify-a-syrian-chemical-attack.html?_r=0">de un ataque con armas químicas en Siria</a> mediante el análisis de información de Google Earth, videos de aficionados, cuentas de testigos oculares y una aplicación de movimiento solar, SunCalc. La información resultante desacreditó las afirmaciones de los líderes políticos rusos y sirios. El equipo de investigaciones visuales del periódico utilizó tácticas similares para construir una línea de tiempo de vídeo detallada de la masacre provocada por un tiroteo en Las Vegas.</li>
  <li>Reporteros de <strong>ProPublica</strong> y <strong>Frontline</strong> <a href="https://www.propublica.org/article/michael-miselis-rise-above-movement-white-supremacist-group-northrop-grumman">investigaron horas de vídeo y miles de datos de publicaciones en redes sociales</a> para identificar a un miembro de un grupo violento de supremacistas blancos, que tenía una autorización de seguridad nacional por su trabajo con un contratista de defensa. Un día después de la publicación de la investigación, el contratista Northrop Grumman despidió a ese empleado.</li>
  <li>En 2017, la <strong>BBC</strong> creó un equipo de verificación, <a href="https://www.bbc.com/news/reality_check">Reality Check,</a> ante la ingente cantidad de material falso y  <em>deepfakes</em> que necesitaban comprobar. En septiembre de 2018, los periodistas lograron verificar mediante técnicas de geolocalización, la procedencia de un vídeo<a href="https://www.poynter.org/fact-checking/2018/how-the-bbc-verified-that-video-of-a-grisly-murder-in-cameroon-step-by-step/"> que mostraba el asesinato de mujeres y niños a manos de soldados en Camerún</a>, y evidenciaron la veracidad de su contenido, frente al escepticismo de las autoridades del país.</li>
  <li>En junio de 2019, la <strong>Unidad de Fact Checking</strong> del <strong>Washington Post</strong> publicó <a href="https://www.washingtonpost.com/graphics/2019/politics/fact-checker/manipulated-video-guide/">una excelente guía sobre cómo detectar vídeos manipulados y <em>deepfakes</em></a>. Sus recomendaciones cubren tres grandes áreas de manipulación: falta de contexto, edición engañosa y transformación maliciosa, y ofrecen valiosos consejos prácticos.</li>
  <li><strong>The Wall Street Journal</strong> ha dado un paso decisivo con la creación de <a href="https://www.niemanlab.org/2018/11/how-the-wall-street-journal-is-preparing-its-journalists-to-detect-deepfakes/">una unidad especializada en combatir <em>deepfakes</em></a> en noviembre de 2018. La unidad, liderada por <strong>Francesco Marconi</strong>, ha establecido un protocolo de trabajo que incluye la verificación de las fuentes, la búsqueda de imágenes previas, el análisis de las grabaciones y la detección de irregularidades tales como la asincronía del audio, la alteración del entorno o la modificación digital. Precisamente <strong>están incorporando herramientas de Inteligencia Artificial</strong> para detectar estos vídeos falsos.</li>
</ul>

<p><img src="{{ site.baseurl }}/images/shots/3-gif-deep-fakes.gif" alt="" /></p>

<p><a href="https://retina.elpais.com/retina/2018/09/17/innovacion/1537177382_367863.html">Como explica en el suplemento Retina <strong>Raúl Arrabales</strong>,</a> experto en Inteligencia Artificial, los propios algoritmos de <em>deep learning</em> pueden usarse para detectar  <em>deepfakes</em> de forma automática e incluso para generar “falsificaciones de laboratorio” que sirvan de entrenamiento para detectores de vídeos, imágenes y documentos falsos. De esta forma se podrán bloquear dichos contenidos o, al menos, advertir al consumidor de que está viendo un vídeo generado por ordenador. Para crear <em>deepfakes</em> de momento <strong>hace falta disponer de un amplio volumen de material previo sobre la persona objeto de la manipulación</strong>. Por eso se han fabricado sobre políticos como Obama o Trump, porque existe un archivo inmenso de grabaciones de sus discursos que facilita la tarea.</p>

<p>Sin embargo, <a href="https://www.xataka.com/inteligencia-artificial/ha-comenzado-carrera-para-crear-tecnologia-capaz-detectar-deepfakes-falsificadores-llevan-ventaja">los algoritmos de detección de  <em>deepfakes</em> siguen yendo por detrás de la tecnología usada para generarlos</a>. Los actores malintencionados actúan mucho más rápidamente que quienes buscan detenerlos, de modo que los  <em>deepfakes</em> resultan cada vez más difíciles de detectar. En <strong>Silicon Valley</strong>, <a href="https://www.latimes.com/politics/story/2019-11-05/deep-fakes-2020-election-silicon-valley-cure">varias tecnológicas llevan tiempo trabajando</a> para contrarrestar los efectos perversos de estas herramientas. Por su parte, <a href="https://elpais.com/tecnologia/2019/10/29/actualidad/1572343240_676009.html"><strong>Google y Facebook</strong> ya han creado una base de datos </a>con miles de archivos audiovisuales manipulados para entrenar a las herramientas de detección automática.</p>

<p><img src="{{ site.baseurl }}/images/shots/4-deep-fakes-zukeberg.jpeg" alt="" /></p>

<p>Numerosos expertos reivindican la necesidad de <strong>implantar un programa intensivo de alfabetización mediática desde la educación secundaria que aborde estas cuestiones.</strong> Algunas iniciativas, como <a href="https://es.unesco.org/sites/default/files/journalism_fake_news_disinformation_print_friendly_0.pdf">este manual sobre “Periodismo, noticias falsas y desinfomación” </a>publicado por la <strong>UNESCO</strong>, contienen directrices muy útiles para verificar contenidos y luchar contra la desinformación. El manual propone cuestiones básicas, como:</p>

<p>- ¿Hay fallos e inconsistencias en el vídeo o en el audio?</p>

<p>- ¿Confías en la fuente?</p>

<p>- ¿Puedes encontrar otras imágenes que corroboren el contenido del vídeo?</p>

<p>- ¿Puedes comprobar la ubicación geográfica, la fecha de grabación, la geolocalización y otro tipo de metadatos?</p>

<p>Nuestra experiencia sobre lo que sucede en el mundo y nuestra capacidad para tomar decisiones al respecto depende de que la información a la que accedemos sea veraz. Cuando se vuelven virales contenidos falsos que se hacen pasar por auténticos, <strong>el riesgo de manipulación es muy elevado, con consecuencias perversas en la opinión pública</strong>. Un problema que plantean los  <em>deepfakes</em> y otras técnicas sofisticadas de desinformación es de qué modo los legisladores y las instituciones pueden preservar el derecho a la información veraz y restringir las técnicas de manipulación de contenidos sin entrar en conflicto con la libertad de expresión y sin ejercer un control contraproducente en internet. Medios y periodistas comparten la responsabilidad de combatir la desinformación generada por estos vídeos cada vez mejor elaborados, <strong>con objeto de salvaguardar la calidad del debate en las sociedades democráticas</strong>.</p>
:ET