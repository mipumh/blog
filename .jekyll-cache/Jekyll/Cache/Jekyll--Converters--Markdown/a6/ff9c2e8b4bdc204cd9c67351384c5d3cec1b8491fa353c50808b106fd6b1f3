I"å3<p>Los contenidos audiovisuales se han convertido en el foco de gran parte de las estrategias de desinformaci√≥n actuales. La aparici√≥n de herramientas de edici√≥n cada vez m√°s sofisticadas, unida a los continuos avances en las t√©cnicas de inteligencia artificial generativa, han dado lugar a <strong>un escenario comunicativo en el que se cuestiona la autenticidad y veracidad de lo que vemos</strong>. En los √∫ltimos meses hemos sido testigos de <a href="https://www.newtral.es/bulos-imagenes-inteligencia-artificial/20230327/">una oleada de im√°genes falsas</a> sin precedentes, difundidas en las redes sociales. Por suerte, algunas herramientas y trucos pueden ayudarte a detectarlas, como explicamos en este art√≠culo.</p>

<p><img src="/blog/images/shots/desinfovisual.png" alt="" /></p>

<p><sup> Imagen generada con Bing Image Creator</sup></p>

<h3 id="im√°genes-manipuladas-o-descontextualizadas">Im√°genes manipuladas o descontextualizadas¬†</h3>

<p>La b√∫squeda inversa de im√°genes es una potente herramienta para detectar fotograf√≠as manipuladas o descontextualizadas. Esta t√©cnica permite <strong>buscar im√°genes en l√≠nea utilizando un archivo como consulta en vez de palabras clave</strong>. La mayor√≠a de los buscadores, como <a href="https://images.google.com/">Google Im√°genes</a> o <a href="https://yandex.com/images/">Yandex Images</a>, ofrecen esta posibilidad aunque existen herramientas espec√≠ficas que permiten acotar y perfeccionar la b√∫squeda:</p>

<p><a href="https://tineye.com/">TinEye</a>. Empresa de b√∫squeda y reconocimiento de im√°genes especializada en visi√≥n art√≠ficial, reconocimiento de patrones, redes neuronales y aprendizaje autom√°tico. Surgi√≥ como un simple archivo de im√°genes y se ha convertido en una potente herramienta de verificaci√≥n. Su <a href="https://services.tineye.com/TinEyeAPI">API TinEye</a> analiza m√°s de 60 millones de im√°genes en tiempo real, facilitando la <strong>detecci√≥n de im√°genes manipuladas e infracciones de los derechos de autor</strong>. Algunas de sus funcionalidades m√°s interesantes son <a href="https://services.tineye.com/TinEyeAlerts">TinEye Alerts</a>, un sistema de seguimiento que detecta cuando ciertas im√°genes aparecen online, y <a href="https://services.tineye.com/MatchEngine">MatchEngine</a>, centrado en la detecci√≥n de contenido duplicado o modificado. Cuenta con una extensi√≥n para Chrome, Firefox, Edge y Opera.</p>

<p><a href="https://www.invid-project.eu/">InVid Project</a>. Se trata de un conjunto de aplicaciones que permiten detectar, autenticar y comprobar la fiabilidad y exactitud de <strong>archivos de v√≠deo e im√°genes difundidas a trav√©s de las redes sociales</strong>. El proyecto, en el que participan universidades, medios de comunicaci√≥n y empresas tecnol√≥gicas de diferentes regiones de Europa, tiene como objetivo ofrecer una ‚Äúnavaja suiza‚Äù de verificaci√≥n con el objetivo de <strong>ahorrar tiempo y trabajar de forma m√°s eficiente en las tareas de verificaci√≥n</strong>. Actualmente cuentan con una <a href="https://www.invid-project.eu/invid-verification-application/">versi√≥n web</a>, una <a href="https://chrome.google.com/webstore/detail/fake-news-debunker-by-inv/mhccpoafgdgbhnjfhkcmgknndkeenfhe?hl=en">extensi√≥n de Chrome</a> y una <a href="https://www.invid-project.eu/invid-mobile-application/">aplicaci√≥n m√≥vil</a> disponible para iOS y Android. Las t√©cnicas de verificaci√≥n empleadas est√°n basadas en el libro ‚ÄúVerification Handbook‚Äù, un manual de verificaci√≥n elaborado por expertos y periodistas de la BBC, Storyful, ABC y Digital First Media, entre otros. Puedes descargar su <strong>versi√≥n en espa√±ol</strong> <a href="https://verificationhandbook.com/downloads/manual.de.verificacion.pdf">aqu√≠</a>.¬†</p>

<p><img src="https://lh4.googleusercontent.com/Tf0GdQ57zjzWE3sJJhviF_t72KQX3tt-b92zW5A_ZdO80ZJ9NVxldTPSkAHFiJ1me5whyhzWFyJiQh_nn0D0AatIRWAt0YsaeYj9B9TwC4476tcpEVm-A7LBBICONSkmkFKSPBNDwOz7xr2B7sqrrut-KhJ6dHNPq5Mlk2otDgMIXp-FniS8KLYFJCCNXBoL" alt="" /></p>

<p><a href="https://29a.ch/photo-forensics/#clone-detection">Foresincally</a>. Una herramienta m√°s compleja, pero tambi√©n m√°s completa que otras alternativas similares. Basada en t√©cnicas de ‚Äúinvestigaci√≥n forense‚Äù de im√°genes, permite <strong>detectar retoques digitales</strong> mediante funcionalidades como el an√°lisis de ruido, la detecci√≥n de zonas ‚Äúclonadas‚Äù, los cambios en la iluminaci√≥n y el acceso a los metadatos e informaci√≥n de geolocalizaci√≥n. Puedes consultar un videotutorial de manos de su creador <a href="https://www.youtube.com/watch?v=XRCq8CJrI_s&amp;ab_channel=JonasWagner">aqu√≠</a>.¬†</p>

<p><a href="https://firstdraftnews.org/verification-toolbox/">Verification Toolbox</a> de FirstDraftNews. Una sencilla herramienta web que permite <strong>investigar el origen de las im√°genes y v√≠deos alojados en redes sociales</strong> como YouTube, Twitter o Facebook. Aunque el proyecto FirstDraftNews ces√≥ su actividad en 2022, cuenta con numerosos <strong>recursos de monitorizaci√≥n, verificaci√≥n y alfabetizaci√≥n medi√°tica</strong> que merece la pena conocer. Entre ellos, su secci√≥n de ‚Äú<a href="https://firstdraftnews.org/bucket/our-training/">mini cursos</a>‚Äù online, y las gu√≠as ‚Äú<a href="https://firstdraftnews.org/wp-content/uploads/2020/07/Verifying_Online_Information_Digital_AW_ES.pdf?x21167">C√≥mo verificar informaci√≥n encontrada en l√≠nea</a>‚Äù y ‚Äú<a href="https://firstdraftnews.org/wp-content/uploads/2020/07/Information_Disorder_Digital_AW_ES.pdf?x21167">Comprender el desorden informativo</a>‚Äù.¬†</p>

<p><a href="https://www.get-metadata.com/">Get-Metadata</a> y <a href="http://www.extractmetadata.com/es.html">ExtractMetada</a>. A menudo encontramos im√°genes en l√≠nea que, pese a no estar manipuladas, en realidad no muestran aquello que nos quieren hacer creer. En estos casos, analizar la ubicaci√≥n y fecha en la que se tom√≥ la fotograf√≠a suele ser una buena soluci√≥n. Las herramientas gratuitas Get-Metadata y ExtractMetada sirven para <strong>comprobar los metadatos de im√°genes, v√≠deos, documentos, audios</strong> y, en el caso de Get-Metadata, incluso e-books. Su funcionamiento es muy sencillo: tan solo tienes que subir el archivo o indicar su url y esperar. El programa te mostrar√° todos los datos asociados gracias a la informaci√≥n XMP, EXIF e ICC.</p>

<h3 id="el-peligro-de-los-deepfakes-y-las-im√°ganes-generadas-con-ia">El peligro de los <em>deepfakes</em> y las im√°ganes generadas con IA</h3>

<p>En el blog hemos analizado los retos que supone la proliferaci√≥n de <em><a href="https://mip.umh.es/blog/2019/12/01/deepfakes-c%C3%B3mo-los-medios-combaten-la-desinformaci%C3%B3n-m%C3%A1s-sofisticada/">deepfakes</a></em>, una de las estrategias de desinformaci√≥n m√°s sofisticadas. Se trata de una t√©cnica mediante inteligencia artificial que emplea algoritmos de aprendizaje autom√°tico y redes neuronales para <strong>alterar o reemplazar el rostro y la voz de una persona a partir de un v√≠deo existente</strong>. Mediante el uso de grandes cantidades de im√°genes y v√≠deos de la persona que se desea imitar, esta tecnolog√≠a <strong>permite crear contenido audiovisual manipulado sumamente realista y convincente</strong>. Una de las principales preocupaciones es, precisamente, su enorme potencial da√±ino a la hora de crear contenido falso para desacreditar figuras p√∫blicas o simular discursos pol√≠ticos con un gran realismo.¬†</p>

<p>En 2021, la EUROPOL ya alertaba de los <strong>riesgos que supone un mal uso de la inteligencia artificial</strong>, en especial en lo que respecta a la creaci√≥n de contenido audiovisual. En su informe ‚Äú<a href="https://www.europol.europa.eu/cms/sites/default/files/documents/malicious_uses_and_abuses_of_artificial_intelligence_europol.pdf">Malicious Uses and Abuses of Artificial Intelligence</a>‚Äù, elaborado junto al Instituto Interregional de Investigaci√≥n sobre Justicia y Crimen de las Naciones Unidas (UNICRI), definen a los <em>deepfakes</em> como ‚Äúun arma poderosa en las guerras de desinformaci√≥n actuales‚Äù, ya que <strong>abren un nuevo paradigma en el que ya no se puede confiar en lo que se ve o se escucha.</strong>¬†</p>

<div class="video-container">

<iframe width="700" height="415" src="https://www.youtube.com/embed/AmUC4m6w1wo" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>

</div>

<p><br /></p>

<p>Sin embargo, <strong>la inteligencia artificial tambi√©n puede ser la soluci√≥n</strong> para frenar el avance de los contenidos manipulados. La compa√±√≠a estadounidense Intel, en una parte de su proyecto <a href="https://www.intel.com/content/www/us/en/research/blogs/trusted-media.html">Trusted Media</a>, incorpor√≥ en uno de sus procesadores la tecnolog√≠a de detecci√≥n de <em>deepfakes</em> desarrollada por el investigador Ilke Demir y el profesor de la Universidad Estatal de Nueva York, Binghamton Umur Ciftci. Esta tecnolog√≠a, llamada <strong>FakeCatcher</strong>, utiliza t√©cnicas de fotopletismograf√≠a en busca de ‚Äúse√±ales biol√≥gicas‚Äù (como el flujo sangu√≠neo de la piel) para determinar si quien aparece en la imagen es una persona real o est√° generada de forma virtual. Los investigadores aseguran obtener resultados superiores al 90% en todos los datasets empleados <a href="https://ieeexplore.ieee.org/document/9141516">en el estudio</a>.¬†</p>

<p>Otra iniciativa similar es el proyecto <strong>DepthFake</strong>, llevado a cabo por un grupo de investigaci√≥n de la Sapienza Universit√† di Roma. En este caso, los investigadores <strong>combinan las t√©cnicas tradicionales de an√°lisis del color con los <a href="https://www.xatakafoto.com/software/asi-funciona-esta-inteligencia-artificial-que-analiza-genera-mapas-profundidad-fotografias">mapas de profundidad</a></strong> para detectar inconsistencias en las im√°genes. Mientras que los mapas de profundidad proporcionan informaci√≥n tridimensional sobre una escena, las im√°genes RGB ofrecen informaci√≥n acerca del color. Al combinar estas dos fuentes de datos, <strong>los algoritmos de detecci√≥n analizan las caracter√≠sticas y anomal√≠as espec√≠ficas que pueden revelar la presencia de una imagen falsa o manipulada</strong>. Por ejemplo, mediante cambios en la iluminaci√≥n, la consistencia espacial o las distorsiones en la perspectiva.¬†</p>

<p>Sin embargo, aunque ambas t√©cnicas facilitan el proceso y son clave a la hora de analizar un gran volumen de datos, <strong>algunos trucos pueden ayudarnos a detectar <em>deepfakes</em></strong> de manera m√°s ‚Äútradicional‚Äù. Los expertos coinciden en que, cuando entra en juego la inteligencia artificial, <strong>la respuesta est√° en los detalles</strong>. Los ojos son el primer elemento a tener en cuenta. El n√∫mero de parpadeos y la forma en que lo hace (a menudo forzada y poco natural), pueden darnos una pista de que algo anda mal. Otro detalle importante es el interior de la boca. <strong>Las tecnolog√≠as de creaci√≥n de <em>deepfakes</em> tienen problemas a la hora de reproducir la lengua y los dientes</strong> cuando la persona est√° hablando. Las texturas, el n√∫mero y la forma de los dientes, son otro aspecto clave. Adem√°s, si la persona es famosa, podemos fijarnos en otros detalles como la desaparici√≥n o aparici√≥n de lunares, l√≠neas de expresi√≥n o vello facial poco realista.¬†</p>

<p>¬øY qu√© ocurre con las <strong>fotograf√≠as generadas mediante inteligencia artificial</strong>? Eso nos dar√≠a para otro art√≠culo. Por ahora, aqu√≠ van algunas pinceladas. Al igual que sucedi√≥ con los <em>deepfakes</em>, la reciente oleada de fotograf√≠as generadas con IA plantea nuevos retos, dudas e incertidumbres. Mientras diversos organismos e instituciones internacionales debaten sobre cu√°l es la mejor forma de proceder, numerosos expertos en el √°mbito de la verificaci√≥n comienzan a publicar <strong>gu√≠as y pautas para ayudar a la sociedad a detectar este tipo de im√°genes</strong>. En espa√±ol, son especialmente valiosas las propuestas de <a href="https://maldita.es/malditatecnologia/20230512/consejos-detectar-imagenes-inteligencia-artificial-dalle/">Maldita</a>, <a href="https://www.newtral.es/como-detectar-imagenes-videos-audios-deepfakes-generados-ia/20230331/">Newtral</a> y <a href="https://chequeado.com/ultimas-noticias/como-saber-si-una-imagen-fue-creada-con-inteligencia-artificial/">Chequeado</a>.¬†</p>

<hr />

<p><small>Este art√≠culo es el resultado de la colaboraci√≥n de la investigadora Alba Garc√≠a Ortega en el <a href="https://iberifier.eu/">proyecto europeo IBERIFIER</a>, un observatorio financiado por la Comisi√≥n Europea para la investigaci√≥n sobre el ecosistema medi√°tico y la lucha contra la desinformaci√≥n en Espa√±a y Portugal.&lt;/s small&gt;</small></p>

<p><img src="https://lh4.googleusercontent.com/bTs6FgRTnThLnwCt1k9znNteTi7m0wTzKMw0vlWQ0jgExP-Fa2RBSrXICKLBuLQOIbFdYLod-VXFKHgK1o_akO8iKO2Iw7H0wqL-_l26kIWq4SblFtm-_ijwNoH04mgmHmwej_wDb9liGgB9o9Lwxkm1C6aOQnBGBUKqUK0YXcdKqnsbcMK9rqCsQ_BG9lPx" alt="" /></p>
:ET