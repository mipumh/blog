---
published: true
layout: post
title: Recursos esenciales para el periodista de datos (2). La extracción de información
excerpt: "El periodismo de datos se ha convertido en una de las grandes oportunidades para esta profesión. Los grandes proyectos requieren una importante inversión, pero unos conocimientos básicos, interés y herramientas relativamente sencillas permiten realizar trabajos de gran valor."
author:
  name: Félix Arias
  twitter: cibermensaje
  gplus:  
  bio: Coordinador Nuevas Narrativas
  image: flx.jpg
  link: https://twitter.com/cibermensaje
---
El periodismo de datos se ha convertido en una de las grandes oportunidades para esta profesión. Los grandes proyectos requieren una importante inversión, pero unos conocimientos básicos, interés y herramientas relativamente sencillas permiten realizar trabajos de gran valor.

Eso es lo que [Antonio Delgado](https://twitter.com/adelgado "Perfil de este profesional en Twitter") demostró en el taller de periodismo de datos que impartió en el módulo de [Nuevas narrativas](https://twitter.com/search?q=%23NuevasNarrativas&src=typd "Hashtag en Twitter de esta asignatura") del Máster de Innovación en Periodismo ([MIP](http://mip.umh.es/ "Página de inicio de este proyecto académico")) de la UMH. Aquí, como complemento o aperitivo, se apuntan algunos de los recursos esenciales para empezar a desenvolverse en esta innovadora especialidad.

Una vez que se conoce [cómo encontrar o solicitar la información](mip.umh.es/blog/2014/04/08/recursos_datos/), comienza el proceso de extracción de datos. Cuando resulta imposible obtener archivos en el formato adecuado, resulta imprescindible convertir o arañar (_scrap_) la materia prima. Éste es el orden, de menor a mayor efectividad, propuesto por Antonio Delgado para los principales formatos:

* Papel
* pdf con imágenes.
* pdf con texto.
* html
* txt
* xls
* csv

Cuando se obtienen documentos en papel con gran cantidad de datos, el primer paso suele ser el escaneo. De este modo, se obtiene un pdf con imágenes a las que se les debe aplicar un [Reconocimiento óptico de caracteres](http://es.wikipedia.org/wiki/Reconocimiento_%C3%B3ptico_de_caracteres "Definición de este proceso en Wikipedia") (OCR). Antonio Delgado recomendó los siguientes programas para realizarlo:

* [Google Docs](https://support.google.com/drive/answer/176692?hl=en "Información sobre este servicio") (gratuito).
* [Adobe Acrobat Pro](http://www.adobe.com/es/products/acrobatpro.html "Web sobre este producto") (de pago).
* [ABBYY FineReader OCR software](http://finereader.abbyy.com/ "Web sobre este producto") (de pago).

Cuando se disponga de un pdf con texto, entra en juego lo que se conoce como [_scraping_](http://es.wikipedia.org/wiki/Screen_scraping "Explicación de este proceso en Wikipedia"). Antonio Delgado recomendó los siguientes programas (todos gratuitos):

* [Cometdocs](http://www.cometdocs.com/ "Web inicial de este producto").
* [Zamzar](http://www.zamzar.com/ "Web inicial de este producto").
* [PDF to Excel Online](https://www.pdftoexcelonline.com/ "Web inicial de este producto").
* [PDF to Excel](http://www.pdftoexcel.org/ "Web inicial de este producto")
* [Tabula](http://tabula.nerdpower.org/ "Web inicial de este producto"). Probablemente, el producto que mejor se adapta a estos trabajos porque fue creado precisamente para favorecer el periodismo de datos.

Si los datos están en la web, habitualmente en formato html, existen otras herramientas específicas.

Para el navegador Chrome, se pueden instalar diversas extensiones:

* [Table Capture](https://chrome.google.com/webstore/detail/table-capture/iebpjdmgckacbodjpijphcplhebcmeop "Web inicial de este producto").
* [Scraper](https://chrome.google.com/webstore/detail/scraper/mbigbapnjcgaffohmbkdlecaccepngjd?hl=en "Web inicial de este producto").

En Firefox, destacan éstas otras:

* [Table2clipboard](https://addons.mozilla.org/en-US/firefox/addon/dafizilla-table2clipboard/ "Web inicial de este producto").
* [OutWit Hub](https://addons.mozilla.org/En-us/firefox/addon/outwit-hub/ "Web inicial de este producto").

Y, finalmente, también pueden descargarse estas dos aplicaciones que, aunque resultan algo más complejas, disponen de un mayor número de opciones:

* [Scraper Wiki](https://scraperwiki.com/ "Web inicial de este producto").
* [Import.io](http://import.io/ "Web inicial de este producto").

Como Antonio Delgado señaló, ninguna herramienta se adapta a todas las necesidades. En función de la naturaleza de los datos que se quieran extraer, unas resultan más útiles que otras. Lo importante es que la información incialmente dispersa o inoperante se convierta en una base de datos o una hoja de cálculo desde la que operar.

A partir de este punto, la mayor parte de los trabajos de periodismo de datos requerirán otros tres procesos:

* La limpieza de los datos (3).
* El análisis de la información (4).
* La visualización de datos (5).

Todos ellos se irán desgranando, en breve y poco a poco, en [este blog](http://mip.umh.es/blog/ "Web inicial de este proyecto").